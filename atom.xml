<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>虎哥的博客</title>
  
  
  <link href="https://bohutang.me/atom.xml" rel="self"/>
  
  <link href="https://bohutang.me/"/>
  <updated>2023-12-29T05:55:55.885Z</updated>
  <id>https://bohutang.me/</id>
  
  <author>
    <name>BohuTANG</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2023 -&gt; 2024</title>
    <link href="https://bohutang.me/2023/12/29/bohu-2023/"/>
    <id>https://bohutang.me/2023/12/29/bohu-2023/</id>
    <published>2023-12-28T16:00:00.000Z</published>
    <updated>2023-12-29T05:55:55.885Z</updated>
    
    <content type="html"><![CDATA[<p>这篇博客是<strong>站</strong>着写的，没有借助AI，human-native！</p><h2 id="AI"><a href="#AI" class="headerlink" title="AI"></a>AI</h2><p>自从有了 GPT4，我可以在数据库内核工程师、测试工程师、文档工程师之间轻松切换，做到了如🐯添🪽。同时，也开始影响身边的人如何更好地利用AI。非常希望 2024 年能够基于开源 LLM 做一些有意义的事情。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>2023 年，继续为 <a href="https://github.com/datafuselabs/databend">Databend</a> 贡献了大量代码，虽然与 2022 相比少了一些，但今年的代码更加实用。每次编码，都能感觉到无比的温暖和崇高的使命感，也使我越来越热爱“程序员”这个职业：一台电脑就可以改变世界。</p><h2 id="运动"><a href="#运动" class="headerlink" title="运动"></a>运动</h2><p>2023，滑板成为我锻炼身体的主要方式。每次一个小时的高强度训练就会让我汗流浃背，感觉非常畅快，现在可以完成一些高级且具欣赏性的动作，虽然也发生过一些意外：手指骨折，小腿骨撞墙，不过都已经恢复，对滑板这个充满挑战和冒险的运动热爱不减。</p><h2 id="改变"><a href="#改变" class="headerlink" title="改变"></a>改变</h2><p>2023 一个重大变化是，我把用了十几年的 Ubuntu 系统切到了 MacOS，使我的装备更加轻量，只需要一台 MacBook 就能随时随地完成所有工作，彻底告别了显示器和机械键键盘。</p><h2 id="Databend"><a href="#Databend" class="headerlink" title="Databend"></a>Databend</h2><p>2023年，所有精力依然围绕 <a href="https://github.com/datafuselabs/databend">Databend</a> 展开，致力于让 <a href="https://github.com/datafuselabs/databend">Databend</a> 更加符合 “Bring Compute to Data” 的理念，为用户带来更高的价值，这也为 2024 年实现<a href="https://github.com/datafuselabs/databend/issues/14167">更加宏大的目标</a>打下了坚实基础。</p><h2 id="2024"><a href="#2024" class="headerlink" title="2024"></a>2024</h2><p>预测 2024 年大数据领域将会发生一些结构性的变革，并演化出更加丰富的应用场景，希望 <a href="https://github.com/datafuselabs/databend">Databend</a> 在这一进程中发挥重要作用，继续走在行业前列，为世界更加美好贡献一份力量。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这篇博客是&lt;strong&gt;站&lt;/strong&gt;着写的，没有借助AI，human-native！&lt;/p&gt;
&lt;h2 id=&quot;AI&quot;&gt;&lt;a href=&quot;#AI&quot; class=&quot;headerlink&quot; title=&quot;AI&quot;&gt;&lt;/a&gt;AI&lt;/h2&gt;&lt;p&gt;自从有了 GPT4，我可以在数</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="2023" scheme="https://bohutang.me/tags/2023/"/>
    
  </entry>
  
  <entry>
    <title>Databend 如何利用 GPT-4 进行质量保证 (2024)</title>
    <link href="https://bohutang.me/2023/11/29/databend-gpt4-wizard/"/>
    <id>https://bohutang.me/2023/11/29/databend-gpt4-wizard/</id>
    <published>2023-11-28T16:00:00.000Z</published>
    <updated>2023-11-29T09:52:48.059Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在数据库行业，质量是核心要素。</p><p>Databend 的应用场景广泛，特别是在金融相关领域，其查询结果的准确性对用户至关重要。因此，在快速迭代的过程中，如何确保产品质量，成为我们面临的重大挑战。</p><p>随着 Databend 开源社区的快速发展，新功能的持续增加和现有功能的优化提出了新的测试挑战。我们致力于在每次代码更新中实施严格的测试，确保稳定性并防止任何潜在问题。</p><h2 id="Databend-的测试方法"><a href="#Databend-的测试方法" class="headerlink" title="Databend 的测试方法"></a>Databend 的测试方法</h2><p>为了确保软件的稳定性和可靠性，Databend 的测试方法覆盖从代码级到系统级的各个方面。</p><h3 id="Unit-Tests"><a href="#Unit-Tests" class="headerlink" title="Unit Tests"></a>Unit Tests</h3><p>单元测试作为测试的基石，着重验证代码的基本功能和逻辑。我们在每次代码提交前自动运行单元测试，确保及时捕捉任何潜在问题。</p><h3 id="SQL-Logic-Tests"><a href="#SQL-Logic-Tests" class="headerlink" title="SQL Logic Tests"></a>SQL Logic Tests</h3><p>Databend 引入了大量的 DuckDB、CockroachDB 和 PostgreSQL 的 SQL 逻辑测试（感谢他们）。这些测试覆盖了广泛的 SQL 场景，帮助我们发现并修复潜在问题，保障 SQL 查询的精确性。</p><h3 id="Compatible-Tests"><a href="#Compatible-Tests" class="headerlink" title="Compatible Tests"></a>Compatible Tests</h3><p>兼容性测试确保新版本与旧版本的向后兼容，帮助用户平稳过渡到 Databend 的更新版本，保障业务的连续性和稳定性。</p><h3 id="Perf-Tests"><a href="#Perf-Tests" class="headerlink" title="Perf Tests"></a>Perf Tests</h3><p>Databend 使用 ClickBench hits 数据集和 TPCH-SF100 作为性能指标，通过这些测试来确保每个版本的性能都符合预期。</p><h3 id="Longrun-Tests"><a href="#Longrun-Tests" class="headerlink" title="Longrun Tests"></a>Longrun Tests</h3><p>Longrun 测试专注于数据写入、更新和合并等操作的长期效果，通过监测 CPU 和内存的稳定性，确保 Databend 的长期运行稳定性和可靠性。</p><p>除 Longrun Tests 外，这些测试在每个 GitHub Pull Request 提交时都会执行，以保证任何更改都符合我们的质量标准。</p><p><img src="https://github.com/datafuselabs/databend/assets/172204/61d03938-d778-4e68-94a7-89c302736fab" alt="databend-ci"></p><h2 id="借助-GPT-4-生成测试模型"><a href="#借助-GPT-4-生成测试模型" class="headerlink" title="借助 GPT-4 生成测试模型"></a>借助 GPT-4 生成测试模型</h2><p>尽管已经采用了多种测试方法，Databend 团队始终在寻求创新。近期，我们引入了 GPT-4 来进一步提升测试流程。</p><h3 id="双缝探测模型"><a href="#双缝探测模型" class="headerlink" title="双缝探测模型"></a>双缝探测模型</h3><p>针对涉及核心路径的修改，我们采用双缝探测模型进行验证。这种方法通过比较当前 PR 版本与主分支（main）版本的结果集来进行验证。如果两者结果一致，则可视为无大碍。但这些验证的 SQL 语句的质量至关重要，这正是我们利用 GPT-4 生成的部分。</p><p>首先，我们指导 GPT-4 根据需求推理出随机数据生成方式，如 <a href="https://github.com/datafuselabs/wizard/blob/main/double_check/sql/setup.sql">setup.sql</a> 所示。然后，基于这些数据，GPT-4 进一步生成用于校验的 SQL 语句，例如 <a href="https://github.com/datafuselabs/wizard/blob/main/double_check/sql/check.sql">check.sql</a>。这些验证 SQL 语句可以根据不同场景进行调整。</p><p>接下来，我们在这两个版本的 Databend 上运行这些 SQL 语句，以验证结果集的一致性。</p><h3 id="结果集正确性模型"><a href="#结果集正确性模型" class="headerlink" title="结果集正确性模型"></a>结果集正确性模型</h3><p>为了确保 Databend 的结果集的正确性，我们选择了 Snowflake 作为参考。这一方法包括三个步骤：</p><ol><li>setup.sql：在 Databend 和 Snowflake 上分别构建表并导入随机数据集。</li><li>action.sql：在 Databend 和 Snowflake 上分别执行数据变更操作，如 Replace&#x2F;Merge 等。</li><li>check.sql：在 Databend 和 Snowflake 上分别执行并验证结果。</li></ol><p>这些 SQL 语句都是由 GPT-4 根据 setup.sql 的数据模式生成的，更加复杂和随机，以便更有效地探测潜在的问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Databend 团队通过引入 GPT-4，为测试流程带来了显著的进步。我们已在 Databend Wizard 项目中发布了更多测试集：<br> <a href="https://github.com/datafuselabs/wizard">https://github.com/datafuselabs/wizard</a></p><p>借助这些 GPT-4 生成的测试模型，Databend 的质量和稳定性又前进了一大步，科技是第一生产力。</p><p><img src="https://github.com/datafuselabs/databend/assets/172204/803de020-e328-45d2-8d7c-170c66721333" alt="GPT4-databend"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://github.com/datafuselabs/wizard">datafuselabs&#x2F;wizard</a><br>[2] <a href="https://github.com/datafuselabs/databend">Databend</a><br>[3] <a href="https://www.snowflake.com/">Snowflake</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在数据库行业，质量是核心要素。&lt;/p&gt;
&lt;p&gt;Databend 的应用场景广泛，特别是在金融相关领域，其查询结果的准确性对用户至关重要。因此</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="wizard" scheme="https://bohutang.me/tags/wizard/"/>
    
    <category term="warehouse" scheme="https://bohutang.me/tags/warehouse/"/>
    
    <category term="ChatGPT" scheme="https://bohutang.me/tags/ChatGPT/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse (9) CPU and Memory profiling for Rust</title>
    <link href="https://bohutang.me/2022/12/19/databend-cpu-mem-profling/"/>
    <id>https://bohutang.me/2022/12/19/databend-cpu-mem-profling/</id>
    <published>2022-12-18T16:00:00.000Z</published>
    <updated>2022-12-19T06:42:31.082Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Go 语言里做各种 CPU 和 Memory profiling 非常方便，尤其是火焰图这种可视化，排查问题非常方便，但是在Rust语言里，稍微有些困难，这次就来分享下如何使用工具对 Rust 程序进行 CPU 和 Memory 的火焰图分析。</p><p>为了支持 CPU 和 Memory Profiling，我们需要增加一些 API，比如在 Databend 中，它们的位置在：<a href="https://github.com/datafuselabs/databend/blob/589068f2ae4bfeeaaf1dff955cc6f6bfc4c38920/src/common/http/src/debug/pprof.rs">cpu&#x2F;pprof.rs</a> 和 <a href="https://github.com/datafuselabs/databend/blob/589068f2ae4bfeeaaf1dff955cc6f6bfc4c38920/src/common/http/src/debug/jeprof.rs">mem&#x2F;jeprof.rs</a> 。</p><h2 id="CPU-Profiling"><a href="#CPU-Profiling" class="headerlink" title="CPU Profiling"></a>CPU Profiling</h2><p>我们只需在 Databend 服务器上执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof -http=&quot;0.0.0.0:8081&quot; http://localhost:8080/debug/pprof/profile?seconds=30</span><br></pre></td></tr></table></figure><ul><li><code>localhost:8080</code>， Databend 的管理地址和端口</li><li><code>0.0.0.0:8081</code>，go tool pprof server 地址</li><li><code>seconds=30</code>，采集时间为 30 s</li></ul><p>这样就可以在浏览器中打开地址: <code>&lt;your-ip&gt;:8081/ui/flamegraph</code> 查看 CPU 的火焰图了，非常方便。</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/databend-cpu-flamegraph.png" align="center" /><h2 id="Memory-Profiling"><a href="#Memory-Profiling" class="headerlink" title="Memory Profiling"></a>Memory Profiling</h2><p>Memory 的火焰图要复杂些，需要做一些前置工作。</p><h3 id="1-Enable-memory-profiling"><a href="#1-Enable-memory-profiling" class="headerlink" title="1. Enable memory profiling"></a>1. Enable memory profiling</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cargo build --bin databend-query --release --features memory-profiling</span><br></pre></td></tr></table></figure><h3 id="2-使用-MALLOC-CONF-启动"><a href="#2-使用-MALLOC-CONF-启动" class="headerlink" title="2. 使用 MALLOC_CONF 启动"></a>2. 使用 <code>MALLOC_CONF</code> 启动</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MALLOC_CONF=prof:true,lg_prof_interval:30 ./target/release/databend-query</span><br></pre></td></tr></table></figure><ul><li><a href="https://jemalloc.net/jemalloc.3.html#opt.lg_prof_interval">lg_prof_interval:30</a>, 1GiB(2^30 bytes)生成一次 Dump文件</li></ul><h3 id="3-替换更快的-add2line-rs"><a href="#3-替换更快的-add2line-rs" class="headerlink" title="3. 替换更快的 add2line-rs"></a>3. 替换更快的 add2line-rs</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/gimli-rs/addr2line</span><br><span class="line">cd addr2line</span><br><span class="line">cargo b --examples -r</span><br><span class="line">cp ./target/release/examples/addr2line &lt;your-addr2line-find-with-whereis-addr2line&gt;</span><br></pre></td></tr></table></figure><p>这样你的 jeprof 就会从 30 分钟飞速到 3 秒。</p><h3 id="4-升级-jeprof-到最新版本"><a href="#4-升级-jeprof-到最新版本" class="headerlink" title="4. 升级 jeprof 到最新版本"></a>4. 升级 jeprof 到最新版本</h3><p>由于旧版 jeprof 不支持火焰图的一些参数，需要对 jeprof 进行升级，由于 jeporf 是一个 perl 脚本，升级就比较暴力。<br>首先找出本机的jeprof文件的路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">whereis jeprof</span><br></pre></td></tr></table></figure><p>然后打开<a href="https://raw.githubusercontent.com/jemalloc/jemalloc/dev/bin/jeprof.in">jeprof 最新版</a>，拷贝并覆盖你本机的 jeprof，注意不要覆盖旧版本的这两个参数，否则会执行失败：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">my $JEPROF_VERSION = &quot;5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756&quot;;</span><br><span class="line">my $PPROF_VERSION = &quot;2.0&quot;;</span><br></pre></td></tr></table></figure><h3 id="5-生成火焰图"><a href="#5-生成火焰图" class="headerlink" title="5. 生成火焰图"></a>5. 生成火焰图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jeprof ./databend-query-main ./jeprof.206330.563.i563.heap --collapse | flamegraph.pl --reverse --invert --minwidth 3 &gt; heap.svg</span><br></pre></td></tr></table></figure><ul><li><p><code>flamegraph.pl</code> 需要从 <a href="https://github.com/brendangregg/FlameGraph/blob/master/flamegraph.pl">github</a>下载</p></li><li><p><code>databend-query-main</code>，你的可执行文件路径</p></li><li><p><code>jeprof.206330.563.i563.heap</code>，选取一个heap 文件</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/mem-profiling.png" align="center" /></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="https://github.com/brendangregg/FlameGraph">brendangregg&#x2F;FlameGraph</a><br>[2] <a href="https://github.com/jemalloc/jemalloc/blob/dev/bin/jeprof.in">https://github.com/jemalloc/jemalloc/blob/dev/bin/jeprof.in</a><br>[3] Databend, Cloud Lakehouse: <a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Go 语言里做各种 CPU 和 Memory profiling 非常方便，尤其是火焰图这种可视化，排查问题非常方便，但是在Rust语言里，</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="flamegraph" scheme="https://bohutang.me/tags/flamegraph/"/>
    
    <category term="profiling" scheme="https://bohutang.me/tags/profiling/"/>
    
  </entry>
  
  <entry>
    <title>新冠六天记</title>
    <link href="https://bohutang.me/2022/12/15/covid-22/"/>
    <id>https://bohutang.me/2022/12/15/covid-22/</id>
    <published>2022-12-14T16:00:00.000Z</published>
    <updated>2022-12-15T06:39:42.311Z</updated>
    
    <content type="html"><![CDATA[<p>12 月初北京疫情逐步放开，去咖啡馆办公了几天，结果就中招了，今天基本恢复，记录下全过程。<br>一家人比较难避免，控制好感染时机比较重要，做到互相照顾。</p><h2 id="12-月-10-号，周六，开始发烧"><a href="#12-月-10-号，周六，开始发烧" class="headerlink" title="12 月 10 号，周六，开始发烧"></a>12 月 10 号，周六，开始发烧</h2><p>早上起来感觉嗓子有点不舒服，下午身体开始发冷，体温 37 度，于是在房间隔离，开始戴 N95。</p><p>调皮蛋们在房间门口拉上了警戒线，并贴上了”密接者“告示，玩起了cosplay。</p><p>晚饭时开始升到 38 度，不过食欲正常，就是头疼的厉害，好不容易搞到几个抗原，测试显示阴性。</p><p>半夜烧到 39 度，头疼的非常厉害，做了好多奇怪的梦，这个疼痛很像小时候感冒发烧时的感觉，瞬间想到了方便面或者罐头，上网搜了下黄桃罐头都要买不到了（药就更难买了！），赶紧淘了几袋方便面。</p><h2 id="12-月-11-号，周日，发烧"><a href="#12-月-11-号，周日，发烧" class="headerlink" title="12 月 11 号，周日，发烧"></a>12 月 11 号，周日，发烧</h2><p>黄桃罐头和方便面都没到！</p><p>这天最严重，烧的头痛欲裂，早上测试抗原，已经显示强阳性。食欲正常。</p><p>晚上高烧到了巅峰，超过了 39 度，头疼的几乎睡不着，特别想吃水果（如果有黄桃罐头就好了）。</p><h2 id="12-月-12-号，周一，开始退烧"><a href="#12-月-12-号，周一，开始退烧" class="headerlink" title="12 月 12 号，周一，开始退烧"></a>12 月 12 号，周一，开始退烧</h2><p>经过一晚上的高烧折腾，早上起来嗓子有点不舒服，但是没有大家说的那种”刀片过喉“感觉，吃过早饭嗓子几乎没有任何感觉。<br>测试了下体温，37度多，温度开始下降，食欲正常。</p><h2 id="12-月-13-号，周二，开始退烧"><a href="#12-月-13-号，周二，开始退烧" class="headerlink" title="12 月 13 号，周二，开始退烧"></a>12 月 13 号，周二，开始退烧</h2><p>食欲下降，四肢有点无力，味觉和嗅觉下降。</p><p>小孩开始出现症状，发烧开始。</p><h2 id="12-月-14-号，周三，体温正常"><a href="#12-月-14-号，周三，体温正常" class="headerlink" title="12 月 14 号，周三，体温正常"></a>12 月 14 号，周三，体温正常</h2><p>体温基本正常，开始咳痰，头昏昏沉沉，无味觉和嗅觉。</p><h2 id="12月-15-号，周四，正常"><a href="#12月-15-号，周四，正常" class="headerlink" title="12月 15 号，周四，正常"></a>12月 15 号，周四，正常</h2><p>体温正常，但抗原显示阳性（较弱），不过已经无所谓了，因为家里其他人基本都开始出现症状，轮到我做后勤保障了。</p><p>至此，网上买的黄桃罐头和方便面都没到！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;12 月初北京疫情逐步放开，去咖啡馆办公了几天，结果就中招了，今天基本恢复，记录下全过程。&lt;br&gt;一家人比较难避免，控制好感染时机比较重要，做到互相照顾。&lt;/p&gt;
&lt;h2 id=&quot;12-月-10-号，周六，开始发烧&quot;&gt;&lt;a href=&quot;#12-月-10-号，周六，开始发烧&quot;</summary>
      
    
    
    
    
    <category term="covid" scheme="https://bohutang.me/tags/covid/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（8) 使用 OpenAI ChatGPT 为 Databend 写代码</title>
    <link href="https://bohutang.me/2022/12/10/databend-gpt3-test/"/>
    <id>https://bohutang.me/2022/12/10/databend-gpt3-test/</id>
    <published>2022-12-09T16:00:00.000Z</published>
    <updated>2022-12-10T04:11:36.406Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>马上要进入 2023 了，但是 Databend 社区仍然忙的热火朝天，我们正在让 Databend 成为真正的 Warehouse + Datalake，致力于解决大数据的低成本和易用性问题，让大家在 2023 和未来生活更加美好！</p><p>最近，一直在探索 OpenAI 的 ChatGPT，刚开始只是觉得好玩，写 PPT 的时候用它做了一些辅助，效果还不错，总算找到了一个对个人有用的点。</p><p>经过一番探索，发现 GPT3 的代码能力非常强大，于是琢磨着怎么让”他”跟 Databend 融合起来。</p><h2 id="探索-1"><a href="#探索-1" class="headerlink" title="探索 1"></a>探索 1</h2><h3 id="提优化建议"><a href="#提优化建议" class="headerlink" title="提优化建议"></a>提优化建议</h3><p>早上，给 Databend 写了<a href="https://github.com/datafuselabs/databend/pull/9188/files#diff-a158b9811117e66afe8a09c56e5e3d9d6294309dda8bbb286e15a654adf39a29R234-R251">一段代码(Rust)</a>，目的是限定 CSV 的换行分隔符在：单个 char 或者 <code>\r\n</code>，代码如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">check_record_delimiter</span>(option: &amp;<span class="keyword">mut</span> <span class="type">String</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;()&gt; &#123;</span><br><span class="line">    <span class="keyword">match</span> option.<span class="title function_ invoke__">len</span>() &#123;</span><br><span class="line">        <span class="number">0</span> =&gt; *option = <span class="string">&quot;\n&quot;</span>.<span class="title function_ invoke__">to_string</span>(),</span><br><span class="line">        <span class="number">1</span> =&gt; &#123;&#125;</span><br><span class="line">        <span class="number">2</span> =&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> option != <span class="string">&quot;\r\n&quot;</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="title function_ invoke__">Err</span>(ErrorCode::<span class="title function_ invoke__">InvalidArgument</span>(</span><br><span class="line">                    <span class="string">&quot;record_delimiter with two chars can only be &#x27;\\r\\n&#x27;&quot;</span>,</span><br><span class="line">                ));</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        _ =&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="title function_ invoke__">Err</span>(ErrorCode::<span class="title function_ invoke__">InvalidArgument</span>(</span><br><span class="line">                <span class="string">&quot;record_delimiter can not more than two chars, please use one char or &#x27;\\r\\n&#x27;&quot;</span>,</span><br><span class="line">            ));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">Ok</span>(())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码老感觉什么地方可以再被优化下，于是向 ChatGPT 这个大聪明征求意见：</p><p>me: <code>please improve it</code></p><p>ChatGPT 首先对这段代码做了专业解读：</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/databend-gpt/chatgpt-code.png" align="center"  /><p>第一次给了一个答案，目测没有我写的好 :)，于是再次征求，发现他的代码几乎跟我的一样，这下就放心了。</p><h3 id="编写单元测试"><a href="#编写单元测试" class="headerlink" title="编写单元测试"></a>编写单元测试</h3><p>me: <code>please write a test for it</code></p><p>ChatGPT 果然一步到位，单元测试代码也写的很专业，对代码逻辑的理解很到位，真是结对编程的好搭档，第一次体验到超级 AI 的威力。</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/databend-gpt/chatgpt-ut.png" align="center" /><p>他写的单测代码一行没改放到了我的PR里：<a href="https://github.com/datafuselabs/databend/pull/9188/files#diff-45ce68c9355f0b0479a5ade057fd165f941ab29d11dc32e1e99298ed1a9ec82cR17-R37">这里</a>，真感谢这个大聪明！</p><h2 id="探索-2"><a href="#探索-2" class="headerlink" title="探索 2"></a>探索 2</h2><p>第二个探索是 Databend 的 logic test。</p><p>虽然 Databend 已经有大量的测试用例，是否可以利用 ChatGPT 生成更多的测试用例，进一步提升软件的质量呢？</p><p>还有很多用例是可以改进的，比如这个 <a href="https://github.com/datafuselabs/databend/issues/9184">issue#9184</a> ，基本是一些流程性的 prompt，怎么让 ChatGPT 帮助我们完成？</p><p>这块目前还没有探索出来，不过非常期待这块的进展。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] ChatGPT: <a href="https://chat.openai.com/">https://chat.openai.com/</a><br>[2] Databend, Cloud Lakehouse: <a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;马上要进入 2023 了，但是 Databend 社区仍然忙的热火朝天，我们正在让 Databend 成为真正的 Warehouse + D</summary>
      
    
    
    
    
    <category term="Databend" scheme="https://bohutang.me/tags/Databend/"/>
    
    <category term="GPT3" scheme="https://bohutang.me/tags/GPT3/"/>
    
    <category term="OpenAI" scheme="https://bohutang.me/tags/OpenAI/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（7) 使用 Xor Filter 替换 Bloom Filter 加速查询</title>
    <link href="https://bohutang.me/2022/11/21/databend-xor-filter/"/>
    <id>https://bohutang.me/2022/11/21/databend-xor-filter/</id>
    <published>2022-11-20T16:00:00.000Z</published>
    <updated>2022-12-10T04:09:56.338Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在大数据分析领域，很多优化都是围绕一句话来做：”reduce distance to the data.“</p><p>Bloom Filter Index 的作用是访问 Storage 之前使用布隆索引做下探测，然后决定是否需要从后端读取真正的数据块。</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/xor-filter/bloom-filter.png" align="center" style="zoom:45%;" /><h2 id="有问题的-Bloom-Filter"><a href="#有问题的-Bloom-Filter" class="headerlink" title="有问题的 Bloom Filter"></a>有问题的 Bloom Filter</h2><p>大家所熟悉的数据库，大部分都在使用 Bloom Filter 解决等值查询的问题，避免做一些无用的数据读取。</p><p>Databend 第一版( <a href="https://github.com/datafuselabs/databend/pull/6639">databend#6639</a>) 使用的也是 Bloom Filter 经典算法，经过测试发现了一些问题：<br>Bloom Filter Index 的索引空间占用过大，Bloom Filter Index 大小甚至超过了原始数据大小（为了让用户简单易用，Databend 会自动为某些数据类型创建 Bloom 索引），这样做 Bloom 检测跟直接读取后端数据区别不大，所以并没有太大的性能提升。</p><p>原因是 Bloom Filter 生成时并不知道数据的基数，比如 Boolean 类型，它也会根据数目分配空间，并不会关注基数问题（基数为 2，True or False）。</p><p>于是 Databend  社区开始了新方案的探索之路，初步确定一个可行方案是通过 HyperLoglog 检测出数据唯一度，然后做空间分配。</p><p>9 月份某个周六的 TiDB 用户大会上，Databend 有个展台，跟 xp(@drmingdrmer) 见面（Databend 团队是 Remote 办公，大家线下见面不太容易 😭）重新讨论起这个问题，他想用 Trie 思想来解决，思路挺好，但复杂度较高。</p><p>xp 是 Trie 领域的高手，工程实现来对他来说不是问题，但隐约感觉一些现有技术可以很好的解决这个问题。</p><img src="https://databend-1253727613.cos.ap-singapore.myqcloud.com/blog/xor-filter/tidb-databend.png" align="center" style="zoom:60%;" /><h2 id="高性价比的-Xor-Filter"><a href="#高性价比的-Xor-Filter" class="headerlink" title="高性价比的 Xor Filter"></a>高性价比的 Xor Filter</h2><p>周日进行了一番探索，发现了 Daniel Lemire 团队在 2019 年提出的 Xor Filter 算法: <a href="https://lemire.me/blog/2019/12/19/xor-filters-faster-and-smaller-than-bloom-filters/">Xor Filters: Faster and Smaller Than Bloom Filters</a>，从介绍看效果非常不错。</p><img src="https://lemire.me/blog/wp-content/uploads/2019/12/comparison.png" style="zoom:45%;" /><p>抱着试试看的心理，基于 Rust 版（<a href="https://github.com/prataprc/xorfilter">xorfilter</a>）做了一个测试 （<a href="https://github.com/BohuTANG/databend/commit/b45793c044c17cc6f8706c42bbe21201590f359f">Xor Filter Bench</a>，发现疗效非常不错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">u64: </span><br><span class="line">xor bitmap encode:1230069 bytes, raw:8000000 bytes, ratio:0.15375863</span><br><span class="line"></span><br><span class="line">bool:</span><br><span class="line">xor bitmap encode:61 bytes, raw:1000000 bytes, ratio:0.000061</span><br><span class="line"></span><br><span class="line">string:</span><br><span class="line">xor bitmap encode:123067 bytes, raw:3000000 bytes, ratio:0.041022334</span><br><span class="line"></span><br><span class="line">100000 records of the same key:</span><br><span class="line">xor bitmap encode: 61 bytes, raw:3000000 bytes, ratio:0.000020333333</span><br></pre></td></tr></table></figure><p>于是，在 <a href="https://github.com/datafuselabs/databend/pull/7860">databend#7860</a> 实现了 Bloom Filter 到 Xor Filter 的切换，让我们做一些测试来看看效果。</p><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>Databend: <a href="https://github.com/datafuselabs/databend/releases/tag/v0.8.122-nightly">v0.8.122-nightly</a>，单节点<br>VM: 32 vCPU, 32 GiB (Cloud VM)<br>Object Store: S3<br>数据集: 100 亿记录，350G Raw Data，Xor Filter Index 700MB，索引和数据全部持久化到对象存储<br>表结构:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; desc t10b;</span><br><span class="line">+-------+-----------------+------+---------+-------+</span><br><span class="line">| Field | Type            | Null | Default | Extra |</span><br><span class="line">+-------+-----------------+------+---------+-------+</span><br><span class="line">| c1    | BIGINT UNSIGNED | NO   | 0       |       |</span><br><span class="line">| c2    | VARCHAR         | NO   |         |       |</span><br><span class="line">+-------+-----------------+------+---------+-------+</span><br></pre></td></tr></table></figure><h3 id="部署-Databend"><a href="#部署-Databend" class="headerlink" title="部署 Databend"></a>部署 Databend</h3><p><strong>Step1：下载<a href="https://databend.rs/download">安装包</a></strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/datafuselabs/databend/releases/download/v0.8.122-nightly/databend-v0.8.122-nightly-x86_64-unknown-linux-musl.tar.gz .</span><br><span class="line">tar zxvf databend-v0.8.122-nightly-x86_64-unknown-linux-musl.tar.gz</span><br></pre></td></tr></table></figure><p>解压后目录结构：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">tree</span><br><span class="line">.</span><br><span class="line">├── bin</span><br><span class="line">│   ├── databend-meta</span><br><span class="line">│   ├── databend-metabench</span><br><span class="line">│   ├── databend-metactl</span><br><span class="line">│   └── databend-query</span><br><span class="line">├── configs</span><br><span class="line">│   ├── databend-meta.toml</span><br><span class="line">│   └── databend-query.toml</span><br><span class="line">├── readme.txt</span><br><span class="line">└── scripts</span><br><span class="line">    ├── start.sh</span><br><span class="line">    └── stop.sh</span><br></pre></td></tr></table></figure><p><strong>Step2：启动 Databend Meta</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/databend-meta -c configs/databend-meta.toml</span><br></pre></td></tr></table></figure><p><strong>Step3：配置 Databend Query</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim configs/databend-query.toml</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">... ...</span><br><span class="line"></span><br><span class="line">[meta]</span><br><span class="line">endpoints = [&quot;127.0.0.1:9191&quot;]</span><br><span class="line">username = &quot;root&quot;</span><br><span class="line">password = &quot;root&quot;</span><br><span class="line">client_timeout_in_second = 60</span><br><span class="line">auto_sync_interval = 60</span><br><span class="line"></span><br><span class="line"># Storage config.</span><br><span class="line">[storage]</span><br><span class="line"># fs | s3 | azblob | obs</span><br><span class="line">type = &quot;s3&quot;</span><br><span class="line"></span><br><span class="line"># To use S3-compatible object storage, uncomment this block and set your values.</span><br><span class="line"> [storage.s3]</span><br><span class="line">bucket = &quot;&lt;your-bucket-name&gt;&quot;</span><br><span class="line">endpoint_url = &quot;&lt;your-s3-endpoint&gt;&quot;</span><br><span class="line">access_key_id = &quot;&lt;your-key&gt;&quot;</span><br><span class="line">secret_access_key = &quot;&lt;your-access-key&gt;&quot;</span><br></pre></td></tr></table></figure><p>详细部署文档请参考： <a href="https://databend.rs/doc/deploy/deploying-databend">https://databend.rs/doc/deploy/deploying-databend</a></p><p><strong>Step4： 启动 Databend Query</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/databend-query -c configs/databend-query.toml</span><br></pre></td></tr></table></figure><p><strong>Step5： 构造测试数据集</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -h127.0.0.1 -P3307</span><br></pre></td></tr></table></figure><p>构造 100 亿条测试数据(耗时 16 min 0.41 sec):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table t10b as select number as c1, cast(rand() as string) as c2 from numbers(10000000000)</span><br></pre></td></tr></table></figure><p>查询（无任何缓存，数据和索引全部在对象存储）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t10b where  c2=&#x27;0.6622377673133426&#x27;;</span><br><span class="line">+-----------+--------------------+</span><br><span class="line">| c1        | c2                 |</span><br><span class="line">+-----------+--------------------+</span><br><span class="line">| 937500090 | 0.6622377673133426 |</span><br><span class="line">+-----------+--------------------+</span><br><span class="line">1 row in set (20.57 sec)</span><br><span class="line">Read 40000000 rows, 1009.75 MiB in 20.567 sec., 1.94 million rows/sec., 49.10 MiB/sec.</span><br></pre></td></tr></table></figure><p>单节点 Databend 利用 filter 下推，然后使用 Xor Filter 索引做过滤，在 100 亿规模的随机数据上做点式查询，可以在 20s 左右。<br>也可以利用 Databend 的分布式能力来加速点查，Databend 的设计理念是一份数据计算弹性扩展，从单节点扩展到集群模式也非常简单：<a href="https://databend.rs/doc/deploy/expanding-to-a-databend-cluster#deploying-a-new-query-node">Expanding a Standalone Databend</a>。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Arxiv: <a href="https://arxiv.org/abs/1912.08258">Xor Filters: Faster and Smaller Than Bloom and Cuckoo Filters</a><br>[2] Daniel Lemire’s blog: <a href="https://lemire.me/blog/2019/12/19/xor-filters-faster-and-smaller-than-bloom-filters/">Xor Filters: Faster and Smaller Than Bloom Filters</a><br>[3] Databend, Cloud Lakehouse: <a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在大数据分析领域，很多优化都是围绕一句话来做：”reduce distance to the data.“&lt;/p&gt;
&lt;p&gt;Bloom Fil</summary>
      
    
    
    
    
    <category term="Databend" scheme="https://bohutang.me/tags/Databend/"/>
    
    <category term="xor filter" scheme="https://bohutang.me/tags/xor-filter/"/>
    
    <category term="bloom filter" scheme="https://bohutang.me/tags/bloom-filter/"/>
    
  </entry>
  
  <entry>
    <title>虎哥与TokuDB的故事</title>
    <link href="https://bohutang.me/2022/05/20/tokudb/"/>
    <id>https://bohutang.me/2022/05/20/tokudb/</id>
    <published>2022-05-19T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.054Z</updated>
    
    <content type="html"><![CDATA[<p>天天在知乎上装大佬给新手们指点迷津，告诉大家学习数据库技术的方法，今天就来聊聊虎哥是怎么进入数据库圈的，和 TokuDB 的故事。</p><p>TokuDB 又是个什么东东呢？</p><p>TokuDB 是一个“老古董“，在机械硬盘时代曾风靡一时，它有着不错的压缩，同时又兼具着不错的读、写能力，被各大厂用来解决容量+性能问题。</p><p>这个故事还得从 LevelDB 说起。</p><p>2011年，LevelDB 开放源代码，当时虎哥被这个清新的 kv 给吸引住了，很快就把它的源码翻了个底朝天，大概熟悉了这个 kv 的内部运行机制，从这个项目开始虎哥就正式开启了他的数据库之旅。</p><p>一边着手写原型，一边跟踪数据库技术的最新进展，当时虎哥把推上一些跟数据库相关的 tag 几乎都关注了，每天早上第一件事就是翻阅这些 tag 相关的推文，数据库这种高大上的技术太有吸引力了，每天都在琢磨着怎么能快速入门！</p><p>有趣的的事情是从 2012 年开始的，虎哥开始尝试实现 Skip List，然后琢磨怎么优化它，Skip List 玩腻了就开始玩 B-Tree，最后无聊到在饭馆门口等座的时候就可以写一个 B-Tree，当时想：数据库就这？于是决定再实现一个完整版的 kv ，项目代号 <a href="https://github.com/BohuTANG/nessDB">nessDB</a>。</p><p>在研发 nessDB 过程中，偶然发现了来自 MIT CSAIL 的《Cache-Oblivious B-Trees》系列，他们通过对 B-Tree 做一个常数项优化从而让整体 IO 大幅降低，基于这个想法他们创立了 TokuTek 这家公司，全力研发 TokuDB 产品，干活的基本都是老板们最得意的学生，3 个学生做研发，外加贝尔实验室的老手 Rik 做架构（这位老哥是个神人，能力非常了得，贝尔实验室硬核精神的体现者，目前已经退休，前段时间还邀请他加入我们的初创公司，由于家庭原因，暂时无法全职工作）。</p><p>当时 TokuDB 还是闭源产品，很多资料都是来自 TokuTek 官网以及老板们的几篇 Paper，2012 年底终于跟 TokuDB 主程 Leif 取得了联系，每周我们都会通过gtalk 进行沟通，在 Leif 专业的指导下，虎哥在 2013 年实现一个非常简化的 TokuDB(<a href="https://bohutang.me/2020/06/20/clickhouse-and-friends-merge-tree-algo/">Fractal-Tree Index</a>)，感觉到达了人生的巅峰，走路姿势都不一样了，成为了掌握数据库核心技术的人！</p><p>2013 年 4月 22 号，TokuDB 正式开源，虎哥开始研究其源码，最后发现跟之前推测的差不太多，但是 TokuDB 为了集成到 MySQL 作为一个 Storage Engine，做了大量的工作，比如 tokudb-engine 就是对接 MySQL Plugin 层的，而真正核心的是 ft-index，一个基于 Fractal-Tree 实现的 kv 存储。</p><p>随后，虎哥由于工作需要就全面投入 TokuDB 的研发工作，先是给 TokuDB 实现了一个 hot backup，让 Xtrabackup 也可以热备 TokuDB 的数据，这个过程需要对 TokuDB 内核做一些改动，虎哥把这个思路同步给了 TokuTek，结果他们当时的VP Tim 给发了一份邮件：<br><code>Hey, send me your name/address, we owe you something as the &quot;first TokuDB contributor&quot;!</code></p><p>结果他们从美国给邮寄了一个 TokuMX 的T恤，TokuMX 是基于 TokuDB 的 MongoDB（当时的 MongoDB 还在使用 MMAP 苦苦挣扎，TokuMX 当时有不少用户），还有一个小小的 TokuDB 蓝色贴纸，上面简单的印着 “First TokuDB Contributor”。</p><p>虎哥内心是无比激动的，依然记得那个阳光明媚的下午，在繁华的 WFC 收到了一个被磨蜕皮的编织袋，由FedEx承运，这是来自大洋彼岸的关怀！</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/tokutek.jpg" style="zoom:60%;"/><p>随后的一段时间内，开源 TokuDB 都是 TokuTek 在折腾，几乎没有社区可言，这种东西外人很难入手，而且他们的能力极强，重构一个大的模块几周就搞定，虎哥也孤独的维护着公司内部的 TokuDB 分支，修 bug，增加 feature。</p><p>2015 年 4 月份，虎哥盛情邀请 Leif 来中国，带他逛了一些知名景点，临走前一天，Leif 找了后海的一家酒吧，很豪情的说反正回到美国，换汇的人民币也用不着了，咱们不醉不归。</p><p>Leif 边点酒边介绍这个酒的味道以及在美国的欢迎度，每点一个新酒，自己先尝一口后再把口杯转 180 度，俩人整了半天，最后 Leif 透漏一个消息，TokuDB 已经被老板卖给了Percona，他们原班人马一个都不会过去，理由是 bla bla…，Google 给了他们团队发了 Offer，但他发誓这辈子再也不碰 Database 这个行业，说是<strong>太辛苦</strong>，看来 TokuDB 这个事情对他们伤害蛮大。</p><p>话说 TokuDB 被 Percona 收购后，很快成为了一个烂摊子，也慢慢停止维护，他们 CTO 也多次邀请虎哥加入，都被婉拒。</p><p>2016 年，虎哥和 Rik 成立了 <a href="https://github.com/xelabs">XeLabs</a> 组织，负责 TokuDB 版本的持续维护，这个版本被多家公司使用，稳定支撑着上万个 TokuDB 实例运行，最终由于精力有限，项目也逐渐停更，维护 MySQL 版本没那么容易，改一个小地方就需要做一堆测试，好歹 TokuDB 工程质量非常好，bug 已经很少，即使现在使用问题也不大，只是现在是 Cloud Database 的天下，很少有人再去部署 MySQL 了。</p><p>好了，这就是虎哥和 TokuDB 的故事。</p><p>虎哥还有和分布式数据库的故事，和数仓的故事，故事太多了，真惆怅。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;天天在知乎上装大佬给新手们指点迷津，告诉大家学习数据库技术的方法，今天就来聊聊虎哥是怎么进入数据库圈的，和 TokuDB 的故事。&lt;/p&gt;
&lt;p&gt;TokuDB 又是个什么东东呢？&lt;/p&gt;
&lt;p&gt;TokuDB 是一个“老古董“，在机械硬盘时代曾风靡一时，它有着不错的压缩，同时</summary>
      
    
    
    
    
    <category term="tokudb" scheme="https://bohutang.me/tags/tokudb/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（6) 如何简单、高效的进行留存和漏斗分析</title>
    <link href="https://bohutang.me/2022/05/18/databend-cloud-warehouse-retention-and-funnel-analysis/"/>
    <id>https://bohutang.me/2022/05/18/databend-cloud-warehouse-retention-and-funnel-analysis/</id>
    <published>2022-05-17T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.053Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。<br>开源地址：<a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p></blockquote><img src="https://datafuse-1253727613.cos.ap-hongkong.myqcloud.com/learn/databend-funnel.png" align="center" style="zoom:40%;" /><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><b>前言</b></h2><p>随着移动互联网的发展，我们时刻都在生产着数据。</p><p>如果你做了一款 APP，3 月份新增用户 1000 人，你是不是想了解在未来的某些时间段内，这部分用户里有多少人持续使用了你的 APP？</p><p>如果你在经营一个电商，你可能更加关注用户在<code>登录</code>，<code>访问（某个商品）</code>，<code>下单</code>，<code>付款</code>流程里每个环节的转化率，了解用户行为轨迹变化，以精准优化产品设计。比如，如果 Andorid 用户在 <code>下单</code> 到 <code>付款</code>这个环节转化率明显低于其他客户端，说明 Andorid 客户端在 <code>付款</code> 这个环节上存在一些问题。</p><p>这就是我们经常说的用户留存和漏斗转化率分析。</p><p>大部分数仓要满足这两个需求，基本都要写一堆 SQL 来进行复杂表达，且性能低下，因为这两个分析会重度依赖 GROUP BY，百万级数据可能就会在分钟级。</p><p>本篇就来聊聊 Databend 如何做到<strong>简洁</strong>、<strong>高效</strong>的满足这两个需求，使用一个简单的 SQL， 在<strong>千万级</strong>的数据集上也可以轻松搞定。</p><h2 id="留存分析"><a href="#留存分析" class="headerlink" title="留存分析"></a><b>留存分析</b></h2><h3 id="数据表"><a href="#数据表" class="headerlink" title="数据表"></a><b>数据表</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE events(`user_id` INT, `visit_date` DATE);</span><br></pre></td></tr></table></figure><ul><li><code>user_id</code>  - 用户 ID</li><li><code>visit_date</code> - 用户访问日期</li></ul><h3 id="构造数据集"><a href="#构造数据集" class="headerlink" title="构造数据集"></a><b>构造数据集</b></h3><p>构造用户访问记录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># user_id 从 0 到 10000000 在 2022-05-15 访问数据</span><br><span class="line">INSERT INTO events SELECT number AS user_id, &#x27;2022-05-15&#x27; FROM numbers(10000000);</span><br><span class="line"></span><br><span class="line"># user_id 从 0 到 5000000 在 2022-05-16 访问数据</span><br><span class="line">INSERT INTO events SELECT number AS user_id, &#x27;2022-05-16&#x27; FROM numbers(5000000);</span><br><span class="line"></span><br><span class="line"># user_id 从 0 到 100000 在 2022-05-17 访问数据</span><br><span class="line">INSERT INTO events SELECT number As user_id, &#x27;2022-05-17&#x27; FROM numbers(100000);</span><br></pre></td></tr></table></figure><h3 id="留存分析-1"><a href="#留存分析-1" class="headerlink" title="留存分析"></a><b>留存分析</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    sum(r[0]) AS r1,</span><br><span class="line">    sum(r[1]) AS r2,</span><br><span class="line">    sum(r[2]) AS r3</span><br><span class="line">FROM</span><br><span class="line">(</span><br><span class="line">    SELECT</span><br><span class="line">        user_id,</span><br><span class="line">        retention(login_date = &#x27;2022-05-15&#x27;, login_date = &#x27;2022-05-16&#x27;, login_date = &#x27;2022-05-17&#x27;) AS r</span><br><span class="line">    FROM events</span><br><span class="line">    GROUP BY user_id</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这里使用 <a href="https://databend.rs/doc/reference/functions/aggregate-functions/aggregate-retention">Databend retention</a> 函数轻松搞定：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----------+---------+--------+</span><br><span class="line">| r1       | r2      | r3     |</span><br><span class="line">+----------+---------+--------+</span><br><span class="line">| 10000000 | 5000000 | 100000 |</span><br><span class="line">+----------+---------+--------+</span><br></pre></td></tr></table></figure><ul><li><code>2022-05-15</code> 有 <code>10000000</code> 人访问</li><li><code>2022-05-16</code> 有 <code>5000000</code> 个用户持续访问，用户留存率 <code>5000000/10000000</code> &#x3D; <code>50%</code></li><li><code>2022-05-17</code> 有<code>100000</code>个用户持续访问，用户留存率 <code>100000/10000000</code> &#x3D; <code>10%</code></li></ul><h2 id="漏斗分析"><a href="#漏斗分析" class="headerlink" title="漏斗分析"></a><b>漏斗分析</b></h2><h3 id="数据表-1"><a href="#数据表-1" class="headerlink" title="数据表"></a><b>数据表</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE events(user_id BIGINT, event_name VARCHAR, event_timestamp TIMESTAMP);</span><br></pre></td></tr></table></figure><ul><li><code>user_id</code>  - 用户 ID</li><li><code>event_name</code> - 事件类型：<code>登录</code>， <code>访问</code> ，<code>下单</code> ，<code>付款</code></li><li><code>event_timestamp</code> - 事件时间（<a href="https://databend.rs/doc/reference/data-types/data-type-time-date-types">Databend TIMESTAMP</a> 类型精度是小数点后 6 位， 微秒（microsecond））</li></ul><h3 id="构造数据集-1"><a href="#构造数据集-1" class="headerlink" title="构造数据集"></a><b>构造数据集</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 用户 100123 事件</span><br><span class="line">INSERT INTO events VALUES(100123, &#x27;登录&#x27;, &#x27;2022-05-14 10:01:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100123, &#x27;访问&#x27;, &#x27;2022-05-14 10:02:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100123, &#x27;下单&#x27;, &#x27;2022-05-14 10:04:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100123, &#x27;付款&#x27;, &#x27;2022-05-14 10:10:00&#x27;);</span><br><span class="line"></span><br><span class="line"># 用户 100125 事件</span><br><span class="line">INSERT INTO events VALUES(100125, &#x27;登录&#x27;, &#x27;2022-05-15 11:00:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100125, &#x27;访问&#x27;, &#x27;2022-05-15 11:01:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100125, &#x27;下单&#x27;, &#x27;2022-05-15 11:02:00&#x27;);</span><br><span class="line"></span><br><span class="line"># 用户 100126 事件</span><br><span class="line">INSERT INTO events VALUES(100126, &#x27;登录&#x27;, &#x27;2022-05-15 12:00:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100126, &#x27;访问&#x27;, &#x27;2022-05-15 12:01:00&#x27;);</span><br><span class="line"></span><br><span class="line"># 用户 100127 事件</span><br><span class="line">INSERT INTO events VALUES(100127, &#x27;登录&#x27;, &#x27;2022-05-15 11:30:00&#x27;);</span><br><span class="line">INSERT INTO events VALUES(100127, &#x27;访问&#x27;, &#x27;2022-05-15 11:31:00&#x27;);</span><br></pre></td></tr></table></figure><h3 id="漏斗分析-1"><a href="#漏斗分析-1" class="headerlink" title="漏斗分析"></a><b>漏斗分析</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT</span><br><span class="line">    level,</span><br><span class="line">    count() AS count</span><br><span class="line">FROM</span><br><span class="line">(</span><br><span class="line">    SELECT</span><br><span class="line">        user_id,</span><br><span class="line">        window_funnel(3600000000)(event_timestamp, event_name = &#x27;登录&#x27;, event_name = &#x27;访问&#x27;, event_name = &#x27;下单&#x27;, event_name = &#x27;付款&#x27;) AS level</span><br><span class="line">    FROM events</span><br><span class="line">    GROUP BY user_id</span><br><span class="line">)</span><br><span class="line">GROUP BY level ORDER BY level ASC;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-------+-------+</span><br><span class="line">| level | count |</span><br><span class="line">+-------+-------+</span><br><span class="line">|     2 |     2 |</span><br><span class="line">|     3 |     1 |</span><br><span class="line">|     4 |     1 |</span><br><span class="line">+-------+-------+</span><br></pre></td></tr></table></figure><p>这里使用 <a href="https://databend.rs/doc/reference/functions/aggregate-functions/aggregate-windowfunnel">Databend window_funnel</a> 函数对用户在 1 小时窗口内，进行事件链下钻分析。</p><p>一小时内：有多少用户登录（level-1) –&gt; 有多少用户访问（level-2） –&gt; 有多少用户下单（level-3） –&gt; 有多少用户付款（level-4）</p><p>从结果来看：</p><ul><li><p><code>登录 --&gt; 访问</code> 这条事件链上总共有 2 个用户，<code>100126</code> 和 <code>100127</code></p></li><li><p><code>登录 --&gt; 访问 --&gt; 下单</code> 这条事件链上有 1 位用户，<code>100125</code></p></li><li><p><code>登录 --&gt; 访问 --&gt; 下单 --&gt; 购买</code> 这条事件链上总共有 1 位用户，<code>100123</code></p></li></ul><p>这样我们就可以轻松计算出每个阶段的转化率。</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a><b>性能</b></h2><p>从上面示例可以看出，留存和漏斗分析都重度依赖  <code>GROUP BY user_id</code>，如果 <code>user_id</code> 较多，对 <code>GROUP BY</code>  计算速度有比较高的要求，Databend 在 <code>GROUP BY</code>上做了大量的优化，目前性能已经非常强悍，具体机制可以参考这篇文章 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4NzYzMzk1Mw==&mid=2247484933&idx=1&sn=f6fa2d04e5864602e00b0be4ef163e99">Databend 的 Group By 聚合查询为什么跑的这么快？</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p>Databend 留存（RETENTION）函数和漏斗分析（WINDOW_FUNNEL）函数去年已经实现，把复杂的逻辑进行封装，让用户使用起来更加方便。</p><p>Databend 作为一个新一代云数仓，在设计上做了一个很大的转变：<strong>数据不再是重心，用户的体验才是</strong>。</p><p>对于一个数仓产品，相信大部分用户都希望：</p><ul><li>不再为存储空间发愁</li><li>不再为计算资源发愁</li><li>开箱即用，真正的按需、按量付费</li></ul><p>随着云基础设施的发展，我们在 Databend Platform 里让这一切都变成了可能。</p><p>基于开源 <a href="https://github.com/datafuselabs/databend">Databend</a> 内核、AWS EC2 计算资源、S3 的对象存储，加上自研的 Serverless Infrastructure，Databend 团队即将推出他们的第一个企业级产品：Databend Platform。</p><p>来，让我们一起看看在 Databend Platform 里如何做漏斗分析：</p><ol><li>选择 Worksheet</li><li>选择休眠的 Warehouse</li><li>执行漏斗分析 SQL，自动唤醒 Warehouse</li><li>Warehouse 自动休眠</li><li>就是这么简单</li></ol><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/blog-window-funnel.gif" align="center" style="zoom:45%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。&lt;br&gt;开源地址：&lt;a href=&quot;https://github.com/datafus</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="user retention" scheme="https://bohutang.me/tags/user-retention/"/>
    
    <category term="window funnel" scheme="https://bohutang.me/tags/window-funnel/"/>
    
    <category term="funnel conversion" scheme="https://bohutang.me/tags/funnel-conversion/"/>
    
  </entry>
  
  <entry>
    <title>使用 ECDSA 替换 RSA 生成 SSH Key</title>
    <link href="https://bohutang.me/2022/05/08/ecdsa-rsa/"/>
    <id>https://bohutang.me/2022/05/08/ecdsa-rsa/</id>
    <published>2022-05-07T16:00:00.000Z</published>
    <updated>2023-10-28T12:29:08.006Z</updated>
    
    <content type="html"><![CDATA[<h2 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h2><p>相信很多同学还在使用 RSA 算法用于生成 SSH 公钥，可能还会纠结选择多少位才足够安全，一般建议是 4096 bits:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure><p>这样我们的公钥(public key) 就会非常长：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat test_rsa_4096.pub</span><br><span class="line"></span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCXlH8OxqMFhv2+En10yV2ZorDzRFXQm9pPuWQ8G5iu+cUpyhwDoKnd+l6PCZTrCgcVJgLSsVAVbZ3CK6Qnoj3TDQl4yaj90UasmivWM2INc2hObr5P2y2AqWnnZBXmxpoUGZPz/9323JalC+m/EwXNcdrC5JzgD083BC0ykfB801vcAzrZwsnbKfCUsGfUNP9mco3+hFwTqgfJxEvmI3X6hbGIGY1d2QbGMLrs3JYVsfRzJDjFaYOSwXZR6pM5uUCKENt9hOmVUZfuZqvlzLZX95yc53a6qNgOJhzaFZYz3wD2gY0dNp1boGnAtXsLqEnqtm9skp05iMuT01B9WrKEOZG5rsRZDh3bYXJ8ZP0lO/RbStuBczd8ZgObb32NfUyHG2JObDpm9mjsvWZqJxJbT5l/6vMXu8hQ6ikDrf6R33PRcRdbUIrAOpDUrfBxjkUonxjqqEbHhpcAlMWNJ4qcjtjvSnLOhH9GBn5KCnFJ7VIbyXc+Gj9AAp9xuV/9jv1R7CathkS2QrC5s9pFY3I24mFevpkioEeJYPAYUTuFBenWg5MdFK99FYO44wjmFa/RxwEQtYFXV+RybTJTC0eDpjK1u3w7LVm2JjEVoSfOJIKt9yZQn5Fm0kmueBz5aQ4CzZNoZBMKr7TT0dX9cJoANzd19uM4uCV6HRVJmQyz4Q== your_email@example.com</span><br></pre></td></tr></table></figure><h2 id="Ed25519"><a href="#Ed25519" class="headerlink" title="Ed25519"></a>Ed25519</h2><p>其实，有一些更先进的算法，比 RSA 更安全，公钥更简短，随着区块链的普及，它们正慢慢被更多的人接受，比如 Ed25519，虽然它只有 256 bit，但安全性比 RSA 3072 还要高。</p><p>Ed25519 SSH Key 生成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot;</span><br></pre></td></tr></table></figure><p>公钥：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat test_ed25519.pub </span><br><span class="line">ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIGcMXqCXtcjny9gXV1NDmwArHy0AgJs+R7N6XpOutviw your_email@example.com</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Github 已经默认推荐大家使用 Ed25519: <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent">https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent</a></p><p>Ed25519 是一个椭圆曲线，非常优美，安全性经过数学严格证明：</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/ed25519.png" style="zoom:45%;">         By Deirdre Connolly in [State of the Curve] (2016)<p>这里有一份目前使用 Ed25519 的列表： <a href="https://ianix.com/pub/ed25519-deployment.html">https://ianix.com/pub/ed25519-deployment.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;RSA&quot;&gt;&lt;a href=&quot;#RSA&quot; class=&quot;headerlink&quot; title=&quot;RSA&quot;&gt;&lt;/a&gt;RSA&lt;/h2&gt;&lt;p&gt;相信很多同学还在使用 RSA 算法用于生成 SSH 公钥，可能还会纠结选择多少位才足够安全，一般建议是 4096 bits:&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="ecdsa" scheme="https://bohutang.me/tags/ecdsa/"/>
    
    <category term="ed25519" scheme="https://bohutang.me/tags/ed25519/"/>
    
    <category term="rsa" scheme="https://bohutang.me/tags/rsa/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（5）从 Git 到 Fuse Engine 存储引擎</title>
    <link href="https://bohutang.me/2022/05/06/databend-cloud-warehouse-fuse-engine/"/>
    <id>https://bohutang.me/2022/05/06/databend-cloud-warehouse-fuse-engine/</id>
    <published>2022-05-05T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.053Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。<br>开源地址：<a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><b>前言</b></h2><p>这篇来介绍下 Databend 底座： Fuse Engine，一个动力澎湃的列式存储引擎，Databend Fuse Engine 在设计之初社区给它的定位是：<b>动力要澎湃，架构要简单，可靠性要高。</b><br>在正式介绍之前，我们先看一组“挑战数据”，Databend Fuse Engine + AWS S3，一个事务在 ~1.5 小时写入了 22.89 TB 原始数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; INSERT INTO ontime_new SELECT * FROM ontime_new;</span><br><span class="line">Query OK, 0 rows affected (1 hour 34 min 36.82 sec)</span><br><span class="line">Read 31619274180 rows, 22.89 TB in 5675.207 sec., 5.57 million rows/sec., 4.03 GB/sec.</span><br></pre></td></tr></table></figure><p>同时，在功能上要满足：</p><ul><li>分布式事务：支持多个计算节点同时读、写同一份数据（存算分离架构首先要解决的问题）</li><li>快照隔离：不同版本数据之间互不影响，方便做 Table Zero-Copy</li><li>回溯能力：可切换到任意一个版本，方便做 Time Travel</li><li>数据合并：合并后生成新版本数据</li><li>简单、健壮：关系通过文件来描述，基于这些文件即可恢复出整个数据系统</li></ul><p>从这些需求出发，你会发现 Fuse Engine 跟 Git “形似”（Git-inspired），在介绍 Fuse Engine 设计之前，我们先来看看 Git 底层是如何工作的。</p><h2 id="Git-工作机制"><a href="#Git-工作机制" class="headerlink" title="Git 工作机制"></a><b>Git 工作机制</b></h2><p>Git 解决了分布式环境下的数据版本管理（data version control）问题，它有隔离（branch）、提交（commit）、回溯（checkout），以及合并（merge）功能，基于 Git 语义完全可以打造出一个分布式存储引擎。市面上也出现一些基于 Git-like 思想而构建的产品，比如 <a href="https://projectnessie.org/">Nessie - Transactional Catalog for Data Lakes</a> 和 <a href="https://lakefs.io/">lakeFS</a> 。</p><p>为了更好的探索 Git 底层工作机制，我们选择从数据库角度出发，使用 Git 语义来完成一系列“数据”操作。</p><ol><li>首先， 准备一个数据文件 <code>cloud.txt</code>，内容为:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2022/05/06, Databend, Cloud</span><br></pre></td></tr></table></figure><ol start="2"><li>把 <code>cloud.txt</code> 数据写到 Git 系统：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;Add olap.txt&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li>Git 为我们生成一个快照，Commit ID 为 <code>7d972c7ba9213c2a2b15422d4f31a8cbc9815f71</code>：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git log </span><br><span class="line">commit 7d972c7ba9213c2a2b15422d4f31a8cbc9815f71 (HEAD)</span><br><span class="line">Author: BohuTANG &lt;overred.shuttler@gmail.com&gt;</span><br><span class="line">Date:   Fri May 6 16:44:21 2022 +0800</span><br><span class="line"></span><br><span class="line">    Add cloud.txt</span><br></pre></td></tr></table></figure><ol start="4"><li>再准备一个新文件 <code>warehouse.txt</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2022/05/07, Databend, Warehouse</span><br></pre></td></tr></table></figure><ol start="5"><li>把 <code>warehouse.txt</code> 数据写到 Git 系统</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m &quot;Add warehouse.txt&quot;</span><br></pre></td></tr></table></figure><ol start="6"><li>Git 为我们生成一个新的快照，Commit ID 为  <code>15af34e4d16082034e1faeaddd0332b3836f1424</code></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">commit 15af34e4d16082034e1faeaddd0332b3836f1424 (HEAD)</span><br><span class="line">Author: BohuTANG &lt;overred.shuttler@gmail.com&gt;</span><br><span class="line">Date:   Fri May 6 17:41:43 2022 +0800</span><br><span class="line"></span><br><span class="line">    Add warehouse.txt</span><br><span class="line"></span><br><span class="line">commit 7d972c7ba9213c2a2b15422d4f31a8cbc9815f71</span><br><span class="line">Author: BohuTANG &lt;overred.shuttler@gmail.com&gt;</span><br><span class="line">Date:   Fri May 6 16:44:21 2022 +0800</span><br><span class="line"></span><br><span class="line">    Add cloud.txt</span><br></pre></td></tr></table></figure><p>到此为止，Git 已经为我们维护了 2 个版本的数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ID 15af34e4d16082034e1faeaddd0332b3836f1424，版本2</span><br><span class="line">ID 7d972c7ba9213c2a2b15422d4f31a8cbc9815f71，版本1</span><br></pre></td></tr></table></figure><p>我们可以根据 Commit ID 进行版本间的任意切换，也就是实现了 Time Travel 和 Table Zero-Copy 功能，那么 Git 底层是如何做到的呢？ 方式也比较简单，它通过引入 3 类对象文件来进行关系描述：</p><ul><li>Commit 文件，用于描述 tree 对象信息</li><li>Tree 文件，用于描述 blob 对象信息</li><li>Blob 文件，用于描述文件信息</li></ul><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/fuse-engien-git.png" align="center" style="zoom:45%;" /><h3 id="HEAD-文件"><a href="#HEAD-文件" class="headerlink" title="HEAD 文件"></a><b>HEAD 文件</b></h3><p>首先，我们需要知道一个 HEAD  指针：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat .git/HEAD</span><br><span class="line">15af34e4d16082034e1faeaddd0332b3836f1424</span><br></pre></td></tr></table></figure><h3 id="Commit-文件"><a href="#Commit-文件" class="headerlink" title="Commit 文件"></a><b>Commit 文件</b></h3><p>Commit 文件会记录跟 commit 相关的一些元数据信息，比如当前 tree 以及 parent，还有提交人等，文件路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.git/objects/15/af34e4d16082034e1faeaddd0332b3836f1424</span><br></pre></td></tr></table></figure><p>文件内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">git cat-file -p 15af34e4d16082034e1faeaddd0332b3836f1424</span><br><span class="line"></span><br><span class="line">tree 576c63e580846fa6df2337c1f074c8d840e0b70a</span><br><span class="line">parent 7d972c7ba9213c2a2b15422d4f31a8cbc9815f71</span><br><span class="line">author BohuTANG &lt;overred.shuttler@gmail.com&gt; 1651830103 +0800</span><br><span class="line">committer BohuTANG &lt;overred.shuttler@gmail.com&gt; 1651830103 +0800</span><br><span class="line"></span><br><span class="line">Add warehouse.txt</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Tree-文件"><a href="#Tree-文件" class="headerlink" title="Tree 文件"></a><b>Tree 文件</b></h3><p>Tree 文件记录当前版本下所有的数据文件，文件路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.git/objects/57/6c63e580846fa6df2337c1f074c8d840e0b70a</span><br></pre></td></tr></table></figure><p>文件内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git cat-file -p 576c63e580846fa6df2337c1f074c8d840e0b70a</span><br><span class="line"></span><br><span class="line">100644 blob 688de5069f9e873c7e7bd15aa67c6c33e0594ddecloud.txt</span><br><span class="line">100644 blob bdea812b9602ed3c6662a2231b3f1e7b52dc1ccbwarehouse.txt</span><br></pre></td></tr></table></figure><h3 id="Blob-文件"><a href="#Blob-文件" class="headerlink" title="Blob 文件"></a><b>Blob 文件</b></h3><p>Blob 文件是原始数据文件，同样可以通过 <code>git cat-file</code> 命令来查看文件内容（如果使用 Git 来管理代码，Blob 就是我们的代码文件）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">git cat-file -p 688de5069f9e873c7e7bd15aa67c6c33e0594dde</span><br><span class="line">2022/05/06, Databend, Cloud</span><br><span class="line"></span><br><span class="line">git cat-file -p bdea812b9602ed3c6662a2231b3f1e7b52dc1ccb</span><br><span class="line">2022/05/07, Databend, Warehouse</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Fuse-Engine"><a href="#Fuse-Engine" class="headerlink" title="Fuse Engine"></a><b>Fuse Engine</b></h2><p>Databend Fuse Engine 在设计上，跟 Git 非常类似，它引入 3 个描述文件：</p><ul><li>Snapshot 文件，用于描述 Segment 对象信息</li><li>Segment 文件，用于描述 Block 对象信息</li><li>Block 文件，用于描述 Parquet 文件信息</li></ul><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/fuse-engine-fuse.png" align="center" style="zoom:45%;" /><p>我们继续在 Fuse Engine 里进行一把刚才在 Git 进行的操作。</p><ol><li>首先<a href="https://databend.rs/doc/reference/sql/ddl/table/ddl-create-table">创建一个表</a>:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE git(file VARCHAR, content VARCHAR);</span><br></pre></td></tr></table></figure><ol start="2"><li><p>把 <code>cloud.txt</code> 数据写到 Fuse Engine</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO git VALUES(&#x27;cloud.txt&#x27;, &#x27;2022/05/06, Databend, Cloud&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>Fuse 为我们生成一个新的 Snapshot ID <code>6450690b09c449939a83268c49c12bb2</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">CALL system$fuse_snapshot(&#x27;default&#x27;, &#x27;git&#x27;);</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">         snapshot_id: 6450690b09c449939a83268c49c12bb2</span><br><span class="line">   snapshot_location: 53/133/_ss/6450690b09c449939a83268c49c12bb2_v1.json</span><br><span class="line">      format_version: 1</span><br><span class="line">previous_snapshot_id: NULL</span><br><span class="line">       segment_count: 1</span><br><span class="line">         block_count: 1</span><br><span class="line">           row_count: 1</span><br><span class="line">  bytes_uncompressed: 68</span><br><span class="line">    bytes_compressed: 351</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>把 <code>warehouse.txt</code> 数据写到 Fuse Engine</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO git VALUES(&#x27;warehouse.txt&#x27;, &#x27;2022/05/07, Databend, Warehouse&#x27;);</span><br></pre></td></tr></table></figure></li><li><p>Fuse Engine 为我们生成一个新的 Snapshot ID <code>efe2687fd1fc48f8b414b5df2cec1e19</code>，并指向前一个 Snapshot ID <code>6450690b09c449939a83268c49c12bb2</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CALL system$fuse_snapshot(&#x27;default&#x27;, &#x27;git&#x27;);</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">         snapshot_id: efe2687fd1fc48f8b414b5df2cec1e19</span><br><span class="line">   snapshot_location: 53/133/_ss/efe2687fd1fc48f8b414b5df2cec1e19_v1.json</span><br><span class="line">      format_version: 1</span><br><span class="line">previous_snapshot_id: 6450690b09c449939a83268c49c12bb2</span><br><span class="line">       segment_count: 2</span><br><span class="line">         block_count: 2</span><br><span class="line">           row_count: 2</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">         snapshot_id: 6450690b09c449939a83268c49c12bb2</span><br><span class="line">   snapshot_location: 53/133/_ss/6450690b09c449939a83268c49c12bb2_v1.json</span><br><span class="line">      format_version: 1</span><br><span class="line">previous_snapshot_id: NULL</span><br><span class="line">       segment_count: 1</span><br><span class="line">         block_count: 1</span><br><span class="line">           row_count: 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>目前为止，Fuse Engine 为我们生成了 2 个版本的数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ID efe2687fd1fc48f8b414b5df2cec1e19，版本2</span><br><span class="line">ID 6450690b09c449939a83268c49c12bb2，版本1</span><br></pre></td></tr></table></figure><p>是不是跟 Git 非常类似？</p></li></ol><h3 id="HEAD"><a href="#HEAD" class="headerlink" title="HEAD"></a><b>HEAD</b></h3><p>跟 Git 一样，Fuse Engine 也需要一个 HEAD 作为入口，查看 Fuse Engine 的 HEAD：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SHOW CREATE TABLE git\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: git</span><br><span class="line">Create Table: CREATE TABLE `git` (</span><br><span class="line">  `file` VARCHAR,</span><br><span class="line">  `content` VARCHAR</span><br><span class="line">) ENGINE=FUSE SNAPSHOT_LOCATION=&#x27;53/133/_ss/efe2687fd1fc48f8b414b5df2cec1e19_v1.json&#x27;</span><br></pre></td></tr></table></figure><p><code>SNAPSHOT_LOCATION</code> 就是 HEAD，默认指向最新的快照 <code>efe2687fd1fc48f8b414b5df2cec1e19</code>，那我们如何切到 ID 为 <code>6450690b09c449939a83268c49c12bb2</code> 的快照数据呢？ 很简单，先查看当前表的 Snapshot 信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CALL system$fuse_snapshot(&#x27;default&#x27;, &#x27;git&#x27;)\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">         snapshot_id: efe2687fd1fc48f8b414b5df2cec1e19</span><br><span class="line">   snapshot_location: 53/133/_ss/efe2687fd1fc48f8b414b5df2cec1e19_v1.json</span><br><span class="line">      format_version: 1</span><br><span class="line">previous_snapshot_id: 6450690b09c449939a83268c49c12bb2</span><br><span class="line">       segment_count: 2</span><br><span class="line">         block_count: 2</span><br><span class="line">           row_count: 2</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">         snapshot_id: 6450690b09c449939a83268c49c12bb2</span><br><span class="line">   snapshot_location: 53/133/_ss/6450690b09c449939a83268c49c12bb2_v1.json</span><br><span class="line">      format_version: 1</span><br><span class="line">previous_snapshot_id: NULL</span><br><span class="line">       segment_count: 1</span><br><span class="line">         block_count: 1</span><br><span class="line">           row_count: 1</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>然后创建一个新表（git_v1）并把 <code>SNAPSHOT_LOCATION</code> 指向相应的 Snapshot 文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE git_v1(`file` VARCHAR, `content` VARCHAR) SNAPSHOT_LOCATION=&#x27;53/133/_ss/6450690b09c449939a83268c49c12bb2_v1.json&#x27;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM git_v1;</span><br><span class="line">+-----------+-----------------------------+</span><br><span class="line">| file      | content                     |</span><br><span class="line">+-----------+-----------------------------+</span><br><span class="line">| cloud.txt | 2022/05/06, Databend, Cloud |</span><br><span class="line">+-----------+-----------------------------+</span><br></pre></td></tr></table></figure><h3 id="Snapshot-文件"><a href="#Snapshot-文件" class="headerlink" title="Snapshot 文件"></a><b>Snapshot 文件</b></h3><p>用于存储 Segment 信息，文件路径 ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">53/133/_ss/efe2687fd1fc48f8b414b5df2cec1e19_v1.json</span><br></pre></td></tr></table></figure><p>文件内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;format_version&quot;:1,</span><br><span class="line">   &quot;snapshot_id&quot;:&quot;efe2687f-d1fc-48f8-b414-b5df2cec1e19&quot;,</span><br><span class="line">   &quot;prev_snapshot_id&quot;:[</span><br><span class="line">      &quot;6450690b-09c4-4993-9a83-268c49c12bb2&quot;,</span><br><span class="line">      1</span><br><span class="line">   ],</span><br><span class="line">   </span><br><span class="line">   &quot;segments&quot;:[</span><br><span class="line">      [</span><br><span class="line">         &quot;53/133/_sg/df56e911eb26446b9f8fac5acc65a580_v1.json&quot;</span><br><span class="line">      ],</span><br><span class="line">      [</span><br><span class="line">         &quot;53/133/_sg/d0bff902b98846469480b23c2a8f93d7_v1.json&quot;</span><br><span class="line">      ]</span><br><span class="line">   ]</span><br><span class="line">   ... ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Segment-文件"><a href="#Segment-文件" class="headerlink" title="Segment 文件"></a><b>Segment 文件</b></h3><p>用于存储 Block 相关信息，文件路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">53/133/_sg/df56e911eb26446b9f8fac5acc65a580_v1.json</span><br></pre></td></tr></table></figure><p>文件内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;format_version&quot;:1,</span><br><span class="line">   &quot;blocks&quot;:[</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;row_count&quot;:1,</span><br><span class="line">         &quot;block_size&quot;:76,</span><br><span class="line">         &quot;file_size&quot;:360,</span><br><span class="line">         &quot;location&quot;:[</span><br><span class="line">            &quot;53/133/_b/ba4a60013e27479e856f739aefeadfaf_v0.parquet&quot;,</span><br><span class="line">            0</span><br><span class="line">         ],</span><br><span class="line">         &quot;compression&quot;:&quot;Lz4Raw&quot;</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br><span class="line">   ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Block-文件"><a href="#Block-文件" class="headerlink" title="Block 文件"></a><b>Block 文件</b></h3><p>Fuse Engine 底层数据使用 Parquet 格式，每个文件内部有多个 Block 组成。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><b>小结</b></h2><p>Databend Fuse Engine 在早期设计（2021 年 10 月）时候，需求很明确，但方案选型还是经历过一段小曲折。当时，Databend 社区调研了市面上大量的 Table Format 方案（比如 Iceberg 等），当时面临的挑战是基于现有方案还是自己造一套？最终选择研发一套简洁的、适合自己的 Storage Engine，但数据存储格式选择 Parquet 标准。<br>在 Fuse Engine 里，我们把 Parquet Footer 单独存放，以减少不必要的 Seek 操作，另外增加了一套更加灵活的索引机制，比如 Aggregation，Join 等都可以有自己的索引来进行加速。</p><p>欢迎体验 Fuse Engine，挂上对象存储，让你体验不一样的大数据分析 <a href="https://databend.rs/doc/deploy">https://databend.rs/doc/deploy</a><br>Databend 开源地址：<a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。&lt;br&gt;开源地址：&lt;a href=&quot;https://github.com/datafus</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="git" scheme="https://bohutang.me/tags/git/"/>
    
    <category term="cloud warehouse" scheme="https://bohutang.me/tags/cloud-warehouse/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（4）Databend 社区如何做测试</title>
    <link href="https://bohutang.me/2021/09/14/databend-cloud-warehouse-how-to-test/"/>
    <id>https://bohutang.me/2021/09/14/databend-cloud-warehouse-how-to-test/</id>
    <published>2021-09-14T07:41:00.000Z</published>
    <updated>2022-08-27T08:25:55.053Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。<br>开源地址：<a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p></blockquote><p>Databend 从第一天就是开源的，测试系统也是基于开源生态所构建，使用了大量的 github CI（免费），已经支撑了我们半年来的快速迭代。</p><p>对于一个开源数据库项目，做到可测试性是加速迭代的不二法宝。一个 Pull Request (通常说的 Patch) 从提交到合并到主干分支，作为一个 Review 人员会比较关注以下几个问题:</p><ol><li>是否会导致功能不正常？</li><li>是否会影响分布式执行？</li><li>是否有跨平台编译问题？</li><li>是否会导致性能下降？</li></ol><p>本篇就从一个 Pull Request 测试周期说起，看看它从创建再到合并入主干分支，Databend 经过了哪些测试，针对上面四个问题做到心中有数，让每个 Pull Request 都有质量保障。</p><h3 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a><strong>单元测试</strong></h3><p>单元测试是最小的测试单元。</p><p>我们每写一个函数都要做到可独立测试，如果这个函数有其他状态依赖，那状态也要是可以 Mock 的。</p><p>在 Databend 中，单元测试都放在一个独立的文件中，比如，x_test.rs:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[test]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">test_y</span>() <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;()&gt; &#123;</span><br><span class="line">   ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目前 Databend 有 500+ 的单元测试，并对一些状态做了全局 Mock，让开发者更加容易的编写测试用例，以从代码层面确保函数执行都符合预期，尽早的发现和解决问题。</p><p>Databend 的单元测试会在 Ubuntu 和 MacOS 两个系统上运行 （Databend 研发主要使用 Mac 和 Ubuntu 两个主力系统）。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/test-unit.png" style="zoom:50%;"/><h3 id="功能测试"><a href="#功能测试" class="headerlink" title="功能测试"></a><strong>功能测试</strong></h3><p>当单元测试通过后，并不一定保证功能是正确的，因为功能通常来说是由多个函数逻辑性的贯穿而成。</p><p>功能测试又分为 Stateless 和 Stateful 两种模型，其中 Stateless 测试模型不需要加载数据集， Stateful 测试模型则需要加载预值的数据集，接下来我们着重看下 Stateless 测试模型。</p><p>Databend 参考了 ClickHouse 的做法，使用表函数 <code>numbers_mt</code> 来便捷的做 Stateless 测试。</p><p>比如这个稍微“复杂”的SQL：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT number%3 as c1, number%2 as c2 FROM numbers_mt(10000) WHERE number &gt; 2 GROUP BY number%3, number%2 ORDER BY c1, c2;</span><br></pre></td></tr></table></figure><p>它先根据条件过滤数据，然后再进行 GROUP BY 分组，最后做一个排序，这个 SQL 执行时，会涉及非常多的函数，所以我们必须有一套便捷的机制来保证多个函数组成的功能也是正确的。</p><p>Databend 是如何做的呢？</p><p>我们会先定义一个需要测试的 SQL 集，x.sql：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> number<span class="operator">%</span><span class="number">3</span> <span class="keyword">as</span> c1, number<span class="operator">%</span><span class="number">2</span> <span class="keyword">as</span> c2 <span class="keyword">FROM</span> numbers_mt(<span class="number">10000</span>) <span class="keyword">WHERE</span> number <span class="operator">&gt;</span> <span class="number">2</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> number<span class="operator">%</span><span class="number">3</span>, number<span class="operator">%</span><span class="number">2</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> c1, c2;</span><br></pre></td></tr></table></figure><p>然后再定义一个预期的结果集，x.result：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0  0</span><br><span class="line">0  1</span><br><span class="line">1  0</span><br><span class="line">1  1</span><br><span class="line">2  0</span><br><span class="line">2  1</span><br></pre></td></tr></table></figure><p>每次做功能测试的时候，Databend 会调用这个 x.sql 文件，然后把得到的结果集和 x.result 文件进行对比，如果有出入则报错并给出提示信息。</p><p>由于 Databend 具备分布式的 MPP 能力，所以功能测试会在单机（Standalone）和 集群（Cluster）两种模式下进行回归测试，以确保 Patch 对功能没有影响。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/test-stateless.png" style="zoom:50%;"/><h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a><strong>性能测试</strong></h3><p>当单元测试和功能测试都通过后，我们还会关注一个重要的指标：这个 Patch 是否导致性能下降？或者是一个性能优化的 Patch 提升了多少性能？</p><p>针对这个问题，Databend 使用数字来做量化，我们只需在 Pull Request 里回复: <code>/run-perf master</code> CI 会自动编译当前分支然后跑相应的性能测试，再跟 master 做对比并生成一份性能对比报告：</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/test-perf-report.png" style="zoom:50%;"/><p>这样，Review 人员就可以根据这个报告清晰的知道当前 Patch 对性能的影响，以确保每个 Patch 在性能上都是可控的。</p><h3 id="编译测试"><a href="#编译测试" class="headerlink" title="编译测试"></a><strong>编译测试</strong></h3><p>Databend 目标是打造一个跨平台的 Cloud Warehouse，所以要求每个 Patch 在以下几个平台都可以正常编译和工作：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- &#123;os: ubuntu-latest, toolchain: stable, target: x86_64-unknown-linux-gnu, cross: false&#125;</span><br><span class="line">- &#123;os: ubuntu-latest, toolchain: stable, target: aarch64-unknown-linux-gnu, cross: true&#125;</span><br><span class="line">- &#123;os: ubuntu-latest, toolchain: stable, target: arm-unknown-linux-gnueabi, cross: true&#125;</span><br><span class="line">- &#123;os: ubuntu-latest, toolchain: stable, target: armv7-unknown-linux-gnueabihf, cross: true&#125;</span><br><span class="line">- &#123;os: macos-latest, toolchain: stable, target: x86_64-apple-darwin, cross: false&#125;</span><br></pre></td></tr></table></figure><p>当这个 CI 跑完后，我们可以明确的知道当前 Patch 对跨版本编译是没有影响的。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h3><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/test-all-passed.png" style="zoom:50%;"/><p>以上所有的 CI 测试都通过后，我们的 Pull Request 才算合格，具备合并到主干分支的条件。</p><p>如果没有这些自动化测试 CI 做保障，每个问题都会消耗 Review 人员大量的精力去做验证，这种模式肯定不可持久，严重影响产品的迭代速度，拖慢社区的节奏。</p><p>Databend 从第一天开始就在努力打造一个可测试的系统，为此我们研发了 test-infra 以及社区协作的 fusebot 机器人，以加速 Databend 产品迭代，尽快提供一个可试用的 Alpha 版本。</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h3><ol><li><a href="https://github.com/datafuselabs/databend">Databend: A Modern Real-Time Data Processing &amp; Analytics DBMS with Cloud-Native Architecture</a></li><li><a href="https://github.com/datafuselabs/databend/tree/master/.github/workflows">Databend Github Workflows</a></li><li><a href="https://github.com/datafuselabs/test-infra">Databend Test Infra</a></li><li><a href="https://github.com/datafuselabs/fusebots">Databend FuseBots</a></li><li><a href="https://clickhouse.tech/docs/en/development/tests/">ClickHouse Testing</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。&lt;br&gt;开源地址：&lt;a href=&quot;https://github.com/datafus</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="cloud warehouse" scheme="https://bohutang.me/tags/cloud-warehouse/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（3）Datafuse 更名为 Databend</title>
    <link href="https://bohutang.me/2021/09/14/datafuse-cloud-warehouse-rename-databend/"/>
    <id>https://bohutang.me/2021/09/14/datafuse-cloud-warehouse-rename-databend/</id>
    <published>2021-09-13T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.054Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。<br>开源地址：<a href="https://github.com/datafuselabs/databend">https://github.com/datafuselabs/databend</a></p></blockquote><p>此篇不算一个技术文章，但是比较重要，因为我们项目改名了，做个说明。</p><h3 id="项目更名原因"><a href="#项目更名原因" class="headerlink" title="项目更名原因"></a><strong>项目更名原因</strong></h3><p>Datafuse 和开源项目 DataFusion 名称在英语语境里比较接近，为了大家未来的发展，我们决定把项目更名为：Databend 。</p><p>由于文化差异导致的一些误解，大家聊开后也就化解了，感谢 Andy 的理解和支持，相信 DataFusion 和  Databend 都有着美好的前景。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/databend-andy-comment.png" style="zoom:50%;"/><h3 id="Databend-寓意"><a href="#Databend-寓意" class="headerlink" title="Databend 寓意"></a><strong>Databend 寓意</strong></h3><p>相对论是 20 世纪最伟大的发现之一，由于物质的存在，时间和空间会发生弯曲（space-time bend），它让人类重新审视时间与空间。我们期望 Databend 的出现，让更多人重新审视数据，发掘出更大的价值。</p><h3 id="关于-「Datafuse-Labs」"><a href="#关于-「Datafuse-Labs」" class="headerlink" title="关于 「Datafuse Labs」"></a><strong>关于 「Datafuse Labs」</strong></h3><p>「Datafuse Labs」成立于 2021 年 3 月，是开源项目 Databend 的背后团队，团队在云原生数据库领域有着丰富的工程经验，同时也是数据库开源社区活跃贡献者，目前在中国、美国、新加坡均设有研发中心，致力于成为业界领先的 Data Cloud 基础软件供应商。</p><h3 id="加入我们"><a href="#加入我们" class="headerlink" title="加入我们"></a><strong>加入我们</strong></h3><ul><li><p>数据库工程师：负责 Databend 内核设计与研发，有丰富的分布式系统经验，熟悉 Rust 或 C++ ，对数据库有着浓厚的兴趣，可 Worldwide Remote 办公。</p></li><li><p>云平台工程师：负责 Databend Cloud 产品设计与研发，有 Kubernetes 开发经验者优先，可 Worldwide Remote 办公。<br>如果对我们感兴趣，简历请投递：<a href="mailto:&#x68;&#x72;&#64;&#x64;&#x61;&#x74;&#97;&#x66;&#117;&#115;&#x65;&#x6c;&#97;&#x62;&#115;&#46;&#x63;&#111;&#x6d;">&#x68;&#x72;&#64;&#x64;&#x61;&#x74;&#97;&#x66;&#117;&#115;&#x65;&#x6c;&#97;&#x62;&#115;&#46;&#x63;&#111;&#x6d;</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Databend 是一个使用 Rust 研发、开源的、完全面向云架构的新式数仓，致力于提供极速的弹性扩展能力，打造按需、按量的 Data Cloud 产品体验。&lt;br&gt;开源地址：&lt;a href=&quot;https://github.com/datafus</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="cloud warehouse" scheme="https://bohutang.me/tags/cloud-warehouse/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Databend and the Cloud Warehouse（2）Databend 架构概览</title>
    <link href="https://bohutang.me/2021/08/21/datafuse-cloud-warehouse-design/"/>
    <id>https://bohutang.me/2021/08/21/datafuse-cloud-warehouse-design/</id>
    <published>2021-08-20T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.054Z</updated>
    
    <content type="html"><![CDATA[<p>Databend 是一个开源的、完全面向云架构的新式数仓，它提供快速的弹性扩展能力，并结合云的弹性、简单性和低成本，使 Data Cloud 构建变得更加容易。Databend 把数据存储在像 AWS S3 ，Azure Blob 这些云上的存储系统，可以使不同的计算节点挂载同一份数据，从而做到较高的弹性，实现对资源的精细化控制。</p><p>Databend 在设计上专注以下能力：</p><ol><li><strong>弹性</strong> 在 Databend 中，存储和计算资源可以按需、按量弹性扩展。</li><li><strong>安全</strong> Databend 中数据文件和网络传输都是端到端加密，并在 SQL 级别提供基于角色的权限控制。</li><li><strong>易用</strong> Databend 兼容 ANSI SQL，并可以使用 MySQL 和 ClickHouse 客户端接入，几乎无学习成本。</li><li><strong>成本</strong> Databend 处理查询非常高效，用户只需要为使用的资源付费。</li></ol><img src="https://datafuse-1253727613.cos.ap-hongkong.myqcloud.com/arch/datafuse-arch-20210817.svg" align="center" /><p>上图是 Databend 的整体架构图，整个系统主要由三大部分组成：<code>Meta service Layer</code>、<code>Compute Layer</code> 和 <code>Storage Layer</code>。</p><h2 id="Meta-Service-Layer"><a href="#Meta-Service-Layer" class="headerlink" title="Meta Service Layer"></a><strong>Meta Service Layer</strong></h2><p>Meta Service 是一个多租户、高可用的分布式 key-value 存储服务，具备事务能力，主要用于存储：</p><ul><li><code>Metadata</code> : 表的元信息、索引信息、集群信息、事务信息等。</li><li><code>Administration</code>：用户系统、用户权限等信息。</li><li><code>Security</code> ：用户登录认证、数据加密等。</li></ul><h2 id="Compute-Layer"><a href="#Compute-Layer" class="headerlink" title="Compute Layer"></a><strong>Compute Layer</strong></h2><p>计算层由多个集群（cluster）组成，不同集群可以承担不同的工作负载，每个集群又有多个计算节点（node）组成，你可以轻松的添加、删除节点或集群，做到资源的按需、按量管理。</p><p>计算节点是计算层的最小构成单元，其中每个计算节点包含以下几个组件：</p><ul><li><strong>执行计划 （Planner）</strong></li></ul><p>根据用户输入的 SQL 生成执行计划，它只是个逻辑表达，并不能真正的执行，而是用于指导整个计算流水线（Pipeline）的编排与生成。<br>比如语句 <code>SELECT number + 1 FROM numbers_mt(10) WHERE number &gt; 8 LIMIT 2</code><br>执行计划：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">datafuse :) EXPLAIN SELECT number + 1 FROM numbers_mt(10) WHERE number &gt; 8 LIMIT 2</span><br><span class="line">┌─explain─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│ Limit: 2                                                                                                                │</span><br><span class="line">│   Projection: (number + 1):UInt64                                                                                       │</span><br><span class="line">│     Expression: (number + 1):UInt64 (Before Projection)                                                                 │</span><br><span class="line">│       Filter: (number &gt; 8)                                                                                              │</span><br><span class="line">│         ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] │</span><br><span class="line">└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p>这个执行计划自下而上分别是 ：</p><p><code>ReadDataSource</code>：表示从哪些文件里读取数据<br><code>Filter</code>: 表示要做 (number &gt; 8) 表达式过滤<br><code>Expression</code>: 表示要做 (number + 1) 表达式运算<br><code>Projection</code>: 表示查询列是哪些<br><code>Limit</code>: 表示取前 2 条数据</p><ul><li><strong>优化器 （Optimizer）</strong></li></ul><p>对执行计划做一些基于规则的优化（A Rule Based Optimizer）, 比如做一些谓词下推或是去掉一些不必要的列等，以使整个执行计划更优。</p><ul><li><strong>处理器 （Processors）</strong></li></ul><p>处理器（Processor）是执行计算逻辑的核心组件。根据执行计划，处理器们被编排成一个流水线（Pipeline），用于执行计算任务。</p><p>整个 Pipeline 是一个有向无环图，每个点是一个处理器，每条边由处理器的 InPort 和 OutPort 相连构成，数据到达不同的处理器进行计算后，通过边流向下一个处理器，多个处理器可以并行计算，在集群模式下还可以跨节点分布式执行，这是 Databend 高性能的一个重要设计。</p><p>例如，我们可以通过 EXPLAIN PIPELINE 来查看：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">datafuse :) EXPLAIN PIPELINE SELECT number + 1 FROM numbers_mt(10000) WHERE number &gt; 8 LIMIT 2</span><br><span class="line">┌─explain───────────────────────────────────────────────────────────────┐</span><br><span class="line">│ LimitTransform × 1 processor                                          │</span><br><span class="line">│   Merge (ProjectionTransform × 16 processors) to (LimitTransform × 1) │</span><br><span class="line">│     ProjectionTransform × 16 processors                               │</span><br><span class="line">│       ExpressionTransform × 16 processors                             │</span><br><span class="line">│         FilterTransform × 16 processors                               │</span><br><span class="line">│           SourceTransform × 16 processors                             │</span><br><span class="line">└───────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p>同样，理解这个 Pipeline 我们自下而上来看：<br><code>SourceTransform</code>：读取数据文件，16 个物理 CPU 并行处理<br><code>FilterTransform</code>：对数据进行 (number &gt; 8) 表达式过滤，16 个物理 CPU 并行处理<br><code>ExpressionTransform</code>：对数据进行 (number + 1) 表达式执行，16 个物理 CPU 并行处理<br><code>ProjectionTransform</code>：对数据处理生成最终列<br><code>LimitTransform</code>：对数据进行 Limit 2 处理，Pipeline 进行折叠，由一个物理 CPU 来执行</p><p>Databend 通过 Pipeline 并行模型，并结合向量计算最大限度的去压榨 CPU 资源，以加速计算。</p><ul><li><strong>缓存 (Cache)</strong></li></ul><p>计算节点使用本地 SSD 缓存数据和索引，以提高数据亲和性来加速计算。<br>缓存的预热方式有：</p><ul><li>LOAD_ON_DEMAND - 按需加载索引或数据块（默认）。</li><li>LOAD_INDEX - 只加载索引。</li><li>LOAD_ALL - 加载全部的数据和索引，对于较小的表可以采取这种模式。</li></ul><h2 id="Storage-Layer"><a href="#Storage-Layer" class="headerlink" title="Storage Layer"></a><strong>Storage Layer</strong></h2><p>Databend 使用 Parquet 列式存储格式来储存数据，为了加快查找（Partition Pruning），Datafuse 为每个 Parquet 提供了自己的索引（根据 Primary Key 生成）：</p><ul><li>min_max.idx Parquet 文件 minimum 和 maximum 值</li><li>sparse.idx 以 N 条记录为颗粒度的稀疏索引</li></ul><p>通过这些索引， 我们可以减少数据的交互，并使计算量大大减少。<br>假设有两个Parquet 文件：<code>f1</code>, <code>f2</code>。<br><code>f1</code> 的 <code>min_max.idx: [3, 5]</code> ；<code>f2</code> 的 <code>min_max.idx: [4, 6]</code> 。如果查询条件为：<code>where x &lt; 4</code> ， 我们只需要 <code>f1</code> 文件就可以，再根据 <code>sparse.idx</code> 索引定位到 <code>f1</code> 文件中的某个数据页。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>Databend 是一个完全面向云架构而设计的新式数仓，它把传统数据库进行解耦，再根据需求组装出一个 Cloud Warehouse，以追求高弹性、低成本为宗旨。</p><p>Databend 目前的聚合函数已经<a href="https://datafuse.rs/overview/performance/">非常高效</a>，基于这些高效的聚合函数（尤其是 Group By），我们实现了模型函数 <a href="https://datafuse.rs/sqlstatement/aggregate-functions/aggregate-windowfunnel/">windowFunnel</a>，用于漏洞模型的高效计算。</p><p>Databend 正处于高速迭代期，欢迎关注我们: <a href="https://github.com/datafuselabs/databend/">https://github.com/datafuselabs/databend/</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Databend 是一个开源的、完全面向云架构的新式数仓，它提供快速的弹性扩展能力，并结合云的弹性、简单性和低成本，使 Data Cloud 构建变得更加容易。Databend 把数据存储在像 AWS S3 ，Azure Blob 这些云上的存储系统，可以使不同的计算节点挂</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="cloud warehouse" scheme="https://bohutang.me/tags/cloud-warehouse/"/>
    
  </entry>
  
  <entry>
    <title>Rust, Datafuse and the Cloud Warehouse（1）云时代数仓架构设计</title>
    <link href="https://bohutang.me/2021/08/08/datafuse-cloud-warehouse-arch/"/>
    <id>https://bohutang.me/2021/08/08/datafuse-cloud-warehouse-arch/</id>
    <published>2021-08-07T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.054Z</updated>
    
    <content type="html"><![CDATA[<p>传统数仓架构不适合云？</p><p>Cloud Warehouse 解决了什么问题？</p><p>Cloud Warehouse 架构应该是什么样？</p><p>带着问题，通过实战，向 Cloud Warehouse 出发。</p><h2 id="Sharding-Warehouse"><a href="#Sharding-Warehouse" class="headerlink" title="Sharding Warehouse"></a><b>Sharding Warehouse</b></h2><p>首先，来看看传统式 Sharding Warehouse 架构，以及它在云上的局限性。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/sharding-warehouse.png" align="center" style="zoom:35%;" /><p>每个 shard 数据区间是固定的，很容易发生数据热点(data skew)问题，一般解决办法：</p><p> ① 提升该 shard 硬件配置，如果热点很难预估，整个集群配置都需要提升，资源上粒度控制粗暴。</p><p> ② 扩容，扩容过程(增加 shard-4)涉及数据迁移，如果数据量大，shard-4 可服务等待时间也会加长。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/sharding-warehouse-scale.png" align="center" style="zoom:35%;" /><p>如果只是把 Sharding Warehouse 简单的搬到云上，资源控制粒度还是很粗糙，很难做到精细化控制，从而无法实现比较精确的按需、按量计费。</p><p>也就说，虽然我们可以随意扩展，但是成本依然高昂。</p><h2 id="Cloud-Warehouse"><a href="#Cloud-Warehouse" class="headerlink" title="Cloud Warehouse"></a><b>Cloud Warehouse</b></h2><p>如果一个 Cloud  Warehouse 满足:</p><ol><li>按需的弹性扩展</li><li>按量的精细化资源控制</li></ol><p>那么它的架构应该是什么样子呢？</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/cloud-warehouse-v1.png" align="center" style="zoom:35%;" /><p>首先它是一个存储和计算分离的架构，其次是计算节点尽量无状态，这样我们可以根据需要添加&#x2F;删除计算节点，算力随时增加和减少，是一个很平滑的过程，不涉及数据的迁移。<br>node-4 基本是 severless 的，可认为是一个进程，运行完毕自动消亡，在调度上可以做到更加精细化。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/cloud-warehouse-v1-scale.png" align="center" style="zoom:35%;" /><p>大家看到这个架构后或许有一个疑问：<br>Cloud Warehouse 架构比传统架构更简单啊 :)<br>Shared Storage 可以是 AWS S3，还可以是 Azure Blob Storage，都让云来做了，compute 使用类似 Presto 的计算引擎不就是完美的 Cloud Warehouse 了吗？</p><p>这里有一个现实问题挡住了通往理想的大道：</p><p>Shared Storage 通常不是为低延迟、高吞吐而设计，偶尔性的抖动也很难控制，如果靠计算引擎蛮力硬刚，这看起来并不是一个好的产品。</p><h2 id="如何设计？"><a href="#如何设计？" class="headerlink" title="如何设计？"></a><b>如何设计？</b></h2><p>首先我们看下 Cloud Warehouse 里的数据有几种状态:</p><ol><li>Persistent data：通常指用户的数据，重度依赖 Shared Storage</li><li>Intermediate data：一般指计算的临时中间结果，比如排序、JOIN等产生的临时数据</li><li>Metadata：object catalogs, table schema, user 等元数据</li></ol><p>既然 Shared Storage 已经假设是不可靠的，那我们尽量减少从 Shared Storage 读取数据好了，增加 Cache 来解决。</p><p>新的问题又来了，这个 Cache 到底 Cache 什么数据呢，是原始的块数据还是索引？是一个全局 Cache 还是计算节点内的 Cache？</p><h3 id="Snowflake-架构"><a href="#Snowflake-架构" class="headerlink" title="Snowflake 架构"></a>Snowflake 架构</h3><p>我们先看看 Snowflake 老大哥的设计:</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/cloud-warehouse-distributed-cache.png" align="center" style="zoom:35%;" /><p>Snowflake 在计算和存储之间加了一个共享的 Ephemeral Storage，主要用于 Intermediate data 存储，同时肩负着 Persistent data cache，好处是缓存可以充分利用，缺点是这个 Distributed Emphemeral Storage 做到 Elastic 同样面临一些挑战，比如多租户情况下资源隔离等问题。</p><h3 id="Datafuse-架构"><a href="#Datafuse-架构" class="headerlink" title="Datafuse 架构"></a>Datafuse 架构</h3><p>Cloud Warehouse 强调状态分离，我们可以把 Persistent data 预先生成足够多的索引放到 Metadata Service，每个计算节点进行订阅，根据需要更新本地的 Cache，这个架构跟 FireBolt 比较相似。</p><p>这是目前比较简单可行的方式，增加计算节点，只要加热 Cache 即可，同样会面临一些挑战，比如海量的索引信息快速同步问题。</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/blog-datafuse/cloud-warehouse-cache-index.png" align="center" style="zoom:35%;" /><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p><a href="https://github.com/datafuselabs/databend">Databend</a> 是一个开源的 Cloud Warehouse，重在计算和状态分离，专注云上的弹性扩展，让大家轻松打造出自己的 Data Cloud。</p><p>很高兴，又开了新系列来讲 Databend，一个把 Rust 和 Cloud 进行连接的 Warehouse 项目，充满乐趣和挑战。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><b>References</b></h2><ol><li><a href="https://github.com/datafuselabs/databend">Databend: A Modern Real-Time Data Processing &amp; Analytics DBMS with Cloud-Native Architecture</a></li><li><a href="https://www.usenix.org/system/files/nsdi20-paper-vuppalapati.pdf">Building An Elastic Query Engine on Disaggregated</a></li><li><a href="http://www.vertica.com/wp-content/uploads/2018/05/Vertica_EON_SIGMOD_Paper.pdf">Eon Mode: Bringing the Vertica Columnar Database to the Cloud</a></li><li><a href="https://www.firebolt.io/resources/firebolt-cloud-data-warehouse-whitepaper">The Firebolt Cloud Data Warehouse Whitepaper</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;传统数仓架构不适合云？&lt;/p&gt;
&lt;p&gt;Cloud Warehouse 解决了什么问题？&lt;/p&gt;
&lt;p&gt;Cloud Warehouse 架构应该是什么样？&lt;/p&gt;
&lt;p&gt;带着问题，通过实战，向 Cloud Warehouse 出发。&lt;/p&gt;
&lt;h2 id=&quot;Sharding-</summary>
      
    
    
    
    
    <category term="databend" scheme="https://bohutang.me/tags/databend/"/>
    
    <category term="Cloud Warehouse" scheme="https://bohutang.me/tags/Cloud-Warehouse/"/>
    
    <category term="snowflake" scheme="https://bohutang.me/tags/snowflake/"/>
    
    <category term="firebolt" scheme="https://bohutang.me/tags/firebolt/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（15）Group By 为什么这么快</title>
    <link href="https://bohutang.me/2021/01/21/clickhouse-and-friends-groupby/"/>
    <id>https://bohutang.me/2021/01/21/clickhouse-and-friends-groupby/</id>
    <published>2021-01-20T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.050Z</updated>
    
    <content type="html"><![CDATA[<p>在揭秘 ClickHouse Group By 之前，先聊聊数据库的性能对比测试问题。<br>在虎哥看来，一个“讲武德”的性能对比测试应该提供什么信息呢？</p><p>首先要尊重客观事实，在什么场景下，x 比 y 快？<br>其次是为什么 x 会比 y 快？ </p><p>如果以上两条都做到了，还有一点也比较重要： x 的优势可以支撑多久？ 是架构等带来的长期优势，还是一袋烟的优化所得，是否能持续跟上自己的灵魂。<br>如果只是贴几个妖艳的数字，算不上是 benchmark，而是 benchmarket。</p><p>好了，回到 Group By 正题。<br>相信很多同学已经体验到 ClickHouse Group By 的出色性能，本篇就来分析下快的原因。<br>首先安慰一下，ClickHouse 的 Group By 并没有使用高大上的黑科技，只是摸索了一条相对较优的方案。</p><h2 id="一条-SQL"><a href="#一条-SQL" class="headerlink" title="一条 SQL"></a><b>一条 SQL</b></h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT sum(number) FROM numbers(10) GROUP BY number % 3</span><br></pre></td></tr></table></figure><p>我们就以这条简单的 SQL 作为线索，看看 ClickHouse 怎么实现 Group By 聚合。</p><h2 id="1-生成-AST"><a href="#1-生成-AST" class="headerlink" title="1. 生成 AST"></a><b>1. 生成 AST</b></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN AST</span><br><span class="line">SELECT sum(number)</span><br><span class="line">FROM numbers(10)</span><br><span class="line">GROUP BY number % 3</span><br><span class="line"></span><br><span class="line">┌─explain─────────────────────────────────────┐</span><br><span class="line">│ SelectWithUnionQuery (children 1)           │</span><br><span class="line">│  ExpressionList (children 1)                │</span><br><span class="line">│   SelectQuery (children 3)                  │</span><br><span class="line">│    ExpressionList (children 1)              │</span><br><span class="line">│     Function sum (children 1)               │  // sum 聚合</span><br><span class="line">│      ExpressionList (children 1)            │</span><br><span class="line">│       Identifier number                     │</span><br><span class="line">│    TablesInSelectQuery (children 1)         │</span><br><span class="line">│     TablesInSelectQueryElement (children 1) │</span><br><span class="line">│      TableExpression (children 1)           │</span><br><span class="line">│       Function numbers (children 1)         │</span><br><span class="line">│        ExpressionList (children 1)          │</span><br><span class="line">│         Literal UInt64_10                   │</span><br><span class="line">│    ExpressionList (children 1)              │</span><br><span class="line">│     Function modulo (children 1)            │  // number % 3 函数</span><br><span class="line">│      ExpressionList (children 2)            │</span><br><span class="line">│       Identifier number                     │</span><br><span class="line">│       Literal UInt64_3                      │</span><br><span class="line">└─────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><h2 id="2-生成-Query-Plan"><a href="#2-生成-Query-Plan" class="headerlink" title="2. 生成 Query Plan"></a><b>2. 生成 Query Plan</b></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN</span><br><span class="line">SELECT sum(number)</span><br><span class="line">FROM numbers(10)</span><br><span class="line">GROUP BY number % 3</span><br><span class="line"></span><br><span class="line">┌─explain───────────────────────────────────────────────────────────────────────┐</span><br><span class="line">│ Expression ((Projection + Before ORDER BY))                                   │ </span><br><span class="line">│   Aggregating                                                                 │ // sum 聚合</span><br><span class="line">│     Expression (Before GROUP BY)                                              │ // number % 3</span><br><span class="line">│       SettingQuotaAndLimits (Set limits and quota after reading from storage) │</span><br><span class="line">│         ReadFromStorage (SystemNumbers)                                       │</span><br><span class="line">└───────────────────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p>代码主要在 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Interpreters/InterpreterSelectQuery.cpp#L1063">InterpreterSelectQuery::executeImpl@Interpreters&#x2F;InterpreterSelectQuery.cpp</a></p><h2 id="3-生成-Pipeline"><a href="#3-生成-Pipeline" class="headerlink" title="3. 生成 Pipeline"></a><b>3. 生成 Pipeline</b></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN PIPELINE</span><br><span class="line">SELECT sum(number)</span><br><span class="line">FROM numbers(10)</span><br><span class="line">GROUP BY number % 3</span><br><span class="line"></span><br><span class="line">┌─explain───────────────────────┐</span><br><span class="line">│ (Expression)                  │</span><br><span class="line">│ ExpressionTransform           │</span><br><span class="line">│   (Aggregating)               │</span><br><span class="line">│   AggregatingTransform        │  // sum 计算</span><br><span class="line">│     (Expression)              │</span><br><span class="line">│     ExpressionTransform       │  // number % 3 计算</span><br><span class="line">│       (SettingQuotaAndLimits) │</span><br><span class="line">│         (ReadFromStorage)     │</span><br><span class="line">└───────────────────────────────┘</span><br></pre></td></tr></table></figure><h2 id="4-执行-Pipeline"><a href="#4-执行-Pipeline" class="headerlink" title=" 4. 执行 Pipeline "></a><b> 4. 执行 Pipeline </b></h2><p>Pipeline 是从底部往上逐一执行。</p><h3 id="4-1-ReadFromStorage"><a href="#4-1-ReadFromStorage" class="headerlink" title="4.1 ReadFromStorage"></a>4.1 ReadFromStorage</h3><p>首先从 ReadFromStorage 执行，生成一个 block1， 数据如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">┌─number─┐</span><br><span class="line">│      0 │</span><br><span class="line">│      1 │</span><br><span class="line">│      2 │</span><br><span class="line">│      3 │</span><br><span class="line">│      4 │</span><br><span class="line">│      5 │</span><br><span class="line">│      6 │</span><br><span class="line">│      7 │</span><br><span class="line">│      8 │</span><br><span class="line">│      9 │</span><br><span class="line">└────────┘</span><br><span class="line">number类型为 UInt64</span><br></pre></td></tr></table></figure><h3 id="4-2-ExpressionTransform"><a href="#4-2-ExpressionTransform" class="headerlink" title="4.2 ExpressionTransform"></a>4.2 ExpressionTransform</h3><p>ExpressionTransform 包含了 2 个 action:</p><ol><li>名字为 number，type 为 INPUT</li><li>名字为 modulo(number, 3)， type 为 FUNCTION</li></ol><p>经过 ExpressionTransform 运行处理后生成一个新的 block2， 数据如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">┌─number─┬─modulo(number, 3)─┐</span><br><span class="line">│      0 │                 0 │</span><br><span class="line">│      1 │                 1 │</span><br><span class="line">│      2 │                 2 │</span><br><span class="line">│      3 │                 0 │</span><br><span class="line">│      4 │                 1 │</span><br><span class="line">│      5 │                 2 │</span><br><span class="line">│      6 │                 0 │</span><br><span class="line">│      7 │                 1 │</span><br><span class="line">│      8 │                 2 │</span><br><span class="line">│      9 │                 0 │</span><br><span class="line">└────────┴───────────────────┘</span><br><span class="line">number 类型为 UInt64</span><br><span class="line">modulo(number, 3) 类型为 UInt8</span><br></pre></td></tr></table></figure><p>代码主要在 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Interpreters/ExpressionActions.cpp#L416">ExpressionActions::execute@Interpreters&#x2F;ExpressionActions.cpp</a></p><h3 id="4-3-AggregatingTransform"><a href="#4-3-AggregatingTransform" class="headerlink" title="4.3 AggregatingTransform"></a>4.3 AggregatingTransform</h3><p>AggregatingTransform 是 Group By 高性能的核心所在。<br>本示例中的 modulo(number, 3) 类型为 UInt8，在做优化上，ClickHouse 会选择使用数组代替 hashtable作为分组，区分逻辑见 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Interpreters/Aggregator.cpp#L526">Interpreters&#x2F;Aggregator.cpp</a></p><p>在计算 sum 的时候，首先会生成一个数组 [1024]，然后做了一个编译展开(代码 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/AggregateFunctions/IAggregateFunction.h#L412-L487">addBatchLookupTable8@AggregateFunctions&#x2F;IAggregateFunction.h</a>):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">static constexpr size_t UNROLL_COUNT = 4;</span><br><span class="line">std::unique_ptr&lt;Data[]&gt; places&#123;new Data[256 * UNROLL_COUNT]&#125;;</span><br><span class="line">bool has_data[256 * UNROLL_COUNT]&#123;&#125;; /// Separate flags array to avoid heavy initialization.</span><br><span class="line"></span><br><span class="line">size_t i = 0;</span><br><span class="line"></span><br><span class="line">/// Aggregate data into different lookup tables.</span><br><span class="line">size_t batch_size_unrolled = batch_size / UNROLL_COUNT * UNROLL_COUNT;</span><br><span class="line">for (; i &lt; batch_size_unrolled; i += UNROLL_COUNT)</span><br><span class="line">&#123;</span><br><span class="line">    for (size_t j = 0; j &lt; UNROLL_COUNT; ++j)</span><br><span class="line">    &#123;</span><br><span class="line">        size_t idx = j * 256 + key[i + j];</span><br><span class="line">        if (unlikely(!has_data[idx]))</span><br><span class="line">        &#123;</span><br><span class="line">            new (&amp;places[idx]) Data;</span><br><span class="line">            has_data[idx] = true;</span><br><span class="line">        &#125;</span><br><span class="line">        func.add(reinterpret_cast&lt;char *&gt;(&amp;places[idx]), columns, i + j, nullptr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>sum(number) … GROUP BY number % 3 计算方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">array[0] = 0 + 3 + 6 + 9 = 18</span><br><span class="line">array[1] = 1 + 4 + 7 = 12</span><br><span class="line">array[2] = 2 + 5 + 8 = 15</span><br></pre></td></tr></table></figure><p>这里只是针对 UInt8 做的一个优化分支，那么对于其他类型怎么优化处理呢？<br>ClickHouse 针对不同的类型分别提供了不同的 hashtable，声势比较浩大（代码见 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Interpreters/Aggregator.h#L68-L103">Aggregator.h</a>）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">using AggregatedDataWithUInt8Key = FixedImplicitZeroHashMapWithCalculatedSize&lt;UInt8, AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithUInt16Key = FixedImplicitZeroHashMap&lt;UInt16, AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithUInt32Key = HashMap&lt;UInt32, AggregateDataPtr, HashCRC32&lt;UInt32&gt;&gt;;</span><br><span class="line">using AggregatedDataWithUInt64Key = HashMap&lt;UInt64, AggregateDataPtr, HashCRC32&lt;UInt64&gt;&gt;;</span><br><span class="line">using AggregatedDataWithShortStringKey = StringHashMap&lt;AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithStringKey = HashMapWithSavedHash&lt;StringRef, AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithKeys128 = HashMap&lt;UInt128, AggregateDataPtr, UInt128HashCRC32&gt;;</span><br><span class="line">using AggregatedDataWithKeys256 = HashMap&lt;DummyUInt256, AggregateDataPtr, UInt256HashCRC32&gt;;</span><br><span class="line">using AggregatedDataWithUInt32KeyTwoLevel = TwoLevelHashMap&lt;UInt32, AggregateDataPtr, HashCRC32&lt;UInt32&gt;&gt;;</span><br><span class="line">using AggregatedDataWithUInt64KeyTwoLevel = TwoLevelHashMap&lt;UInt64, AggregateDataPtr, HashCRC32&lt;UInt64&gt;&gt;;</span><br><span class="line">using AggregatedDataWithShortStringKeyTwoLevel = TwoLevelStringHashMap&lt;AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithStringKeyTwoLevel = TwoLevelHashMapWithSavedHash&lt;StringRef, AggregateDataPtr&gt;;</span><br><span class="line">using AggregatedDataWithKeys128TwoLevel = TwoLevelHashMap&lt;UInt128, AggregateDataPtr, UInt128HashCRC32&gt;;</span><br><span class="line">using AggregatedDataWithKeys256TwoLevel = TwoLevelHashMap&lt;DummyUInt256, AggregateDataPtr, UInt256HashCRC32&gt;;</span><br><span class="line">using AggregatedDataWithUInt64KeyHash64 = HashMap&lt;UInt64, AggregateDataPtr, DefaultHash&lt;UInt64&gt;&gt;;</span><br><span class="line">using AggregatedDataWithStringKeyHash64 = HashMapWithSavedHash&lt;StringRef, AggregateDataPtr, StringRefHash64&gt;;</span><br><span class="line">using AggregatedDataWithKeys128Hash64 = HashMap&lt;UInt128, AggregateDataPtr, UInt128Hash&gt;;</span><br><span class="line">using AggregatedDataWithKeys256Hash64 = HashMap&lt;DummyUInt256, AggregateDataPtr, UInt256Hash&gt;;</span><br></pre></td></tr></table></figure><p>如果我们改成 GROUP BY number*100000 后，它会选择 AggregatedDataWithUInt64Key 的 hashtable 作为分组。</p><p>而且 ClickHouse 提供了一种 Two Level 方式，用语应对有大量分组 key 的情况，Level1 先分大组，Level2 小组可以并行计算。<br>针对 String 类型，根据不同的长度，hashtable 也做了很多优化，代码见 <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Common/HashTable/StringHashMap.h#L78-L82">HashTable&#x2F;StringHashMap.h</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p>ClickHouse 会根据 Group By 的最终类型，选择一个最优的 hashtable 或数组，作为分组基础数据结构，使内存和计算尽量最优。</p><p>这个”最优解“是怎么找到的？从 test 代码可以看出，是不停的尝试、测试验证出来的，浓厚的 bottom-up 哲学范。</p><p>hashtable 测试代码：<a href="https://github.com/ClickHouse/ClickHouse/tree/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Interpreters/tests">Interpreters&#x2F;tests</a></p><p>lookuptable 测试代码： <a href="https://github.com/ClickHouse/ClickHouse/blob/27ddf78ba572b893cb5351541f566d1080d8a9c6/src/Common/tests/average.cpp">tests&#x2F;average.cpp</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在揭秘 ClickHouse Group By 之前，先聊聊数据库的性能对比测试问题。&lt;br&gt;在虎哥看来，一个“讲武德”的性能对比测试应该提供什么信息呢？&lt;/p&gt;
&lt;p&gt;首先要尊重客观事实，在什么场景下，x 比 y 快？&lt;br&gt;其次是为什么 x 会比 y 快？ &lt;/p&gt;
&lt;</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
    <category term="aggregator" scheme="https://bohutang.me/tags/aggregator/"/>
    
    <category term="hashtable" scheme="https://bohutang.me/tags/hashtable/"/>
    
    <category term="groupby" scheme="https://bohutang.me/tags/groupby/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（14）存储计算分离方案与实现</title>
    <link href="https://bohutang.me/2020/09/18/clickhouse-and-friends-compute-storage/"/>
    <id>https://bohutang.me/2020/09/18/clickhouse-and-friends-compute-storage/</id>
    <published>2020-09-17T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.050Z</updated>
    
    <content type="html"><![CDATA[<img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-replicatedmergetree.png" align="center" style="zoom:50%;" /><p><b>最后更新: 2020-09-28</b></p><p>如果多个 ClickHouse server 可以挂载同一份数据(分布式存储等)，并且每个 server 都可写，这样会有什么好处呢？</p><p>首先，我们可以把副本机制交给分布式存储来保障，上层架构变得简单朴素；</p><p>其次，clickhouse-server 可以在任意机器上增加、减少，使存储和计算能力得到充分发挥。</p><p>本文就来探讨一下 ClickHouse 的存储计算分离方案，实现上并不复杂。</p><h2 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a><b>1. 问题</b></h2><p>ClickHouse 运行时数据由两部分组成：<b>内存元数据</b>和<b>磁盘数据</b>。</p><p>我们先看写流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w1. 开始写入数据</span><br><span class="line">w2. 生成内存part信息，并维护part metadata列表</span><br><span class="line">w3. 把part数据写到磁盘</span><br></pre></td></tr></table></figure><p>再来看读流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">r1. 从part metadata定位需要读取的part</span><br><span class="line">r2. 从磁盘读取part数据</span><br><span class="line">r3. 返回给上层数据</span><br></pre></td></tr></table></figure><p>这样，如果 server1 写了一条数据，只会更新自己内存的 part metadata，其他 server 是感知不到的，这样也就无法查询到刚写入的数据。</p><p>存储计算分离，首先要解决的就是内存状态数据的同步问题。</p><p>在 ClickHouse 里，我们需要解决的是内存中 part metadata 同步问题。</p><h2 id="2-内存数据同步"><a href="#2-内存数据同步" class="headerlink" title="2. 内存数据同步"></a><b>2. 内存数据同步</b></h2><p>在上篇 <a href="/2020/09/13/clickhouse-and-friends-replicated-merge-tree/">&lt;ReplicatedMergeTree表引擎及同步机制&gt;</a> 中，我们知道副本间的数据同步机制：<br>首先同步元数据，再通过元数据获取相应part数据。</p><p>这里，我们借用 ReplicatedMergeTree 同步通道，然后再做减法，同步完元数据后跳过 part 数据的同步，因为磁盘数据只需一个 server 做更新(需要 fsync 语义)即可。</p><p>核心代码：<br>MergeTreeData::renameTempPartAndReplace</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (!share_storage)</span><br><span class="line">    part-&gt;renameTo(part_name, true);</span><br></pre></td></tr></table></figure><h2 id="3-演示demo"><a href="#3-演示demo" class="headerlink" title="3. 演示demo"></a><b>3. 演示demo</b></h2><figure class="video_container">  <iframe src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/video/clickhouse-storage-compute.mp4" frameborder="0" allowfullscreen="true"> </iframe></figure><p>script：</p><ol><li>首先起 2 个 clickhouse-server，它们都挂载同一份数据 <code>&lt;path&gt;/home/bohu/work/cluster/d1/datas/&lt;/path&gt;</code></li><li>通过 clickhouse-server1(port 9101) 写入一条记录:(111, 3333)</li><li>通过 clickhouse-server2(port 9102) 进行查询正常</li><li>通过 clickhouse-server2(port 9102) truncate 表</li><li>通过 clickhouse-server1(port 9101) 查询正常</li></ol><h2 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4. 代码实现"></a><b>4. 代码实现</b></h2><p><a href="https://github.com/BohuTANG/ClickHouse/commit/f67d98ef408fda1a359e4fb17848619ef1f6e59b">原型</a><br>需要注意的是，这里只实现了写入数据同步，而且是非常 tricky 的方式。</p><p>由于 DDL 没有实现，所以在 zookeeper 上的注册方式也比较 tricky，demo 里的 replicas 都是手工注册的。</p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a><b>5. 总结</b></h2><p>本文提供一个思路，算是抛砖引玉，同时也期待更加系统的工程实现。</p><p>ClickHouse 暂时还不支持 Distributed Query 功能，如果这个能力支持，ClickHouse 存储计算分离就是一个威力无比的小氢弹。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;img src=&quot;https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-replicatedmergetree.png&quot; align=&quot;center&quot; style=&quot;z</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="replicatedmergetree" scheme="https://bohutang.me/tags/replicatedmergetree/"/>
    
    <category term="storage" scheme="https://bohutang.me/tags/storage/"/>
    
    <category term="compute" scheme="https://bohutang.me/tags/compute/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（13）ReplicatedMergeTree表引擎及同步机制</title>
    <link href="https://bohutang.me/2020/09/13/clickhouse-and-friends-replicated-merge-tree/"/>
    <id>https://bohutang.me/2020/09/13/clickhouse-and-friends-replicated-merge-tree/</id>
    <published>2020-09-12T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.053Z</updated>
    
    <content type="html"><![CDATA[<img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-replicatedmergetree.png" align="center" style="zoom:50%;" /><p><b>最后更新: 2020-09-13</b></p><p>在 MySQL 里，为了保证高可用以及数据安全性会采取主从模式，数据通过 binlog 来进行同步。</p><p>在 ClickHouse 里，我们可以使用 ReplicatedMergeTree 引擎，数据同步通过 zookeeper 完成。</p><p>本文先从搭建一个多 replica 集群开始，然后一窥底层的机制，简单吃两口。</p><h2 id="1-集群搭建"><a href="#1-集群搭建" class="headerlink" title="1. 集群搭建"></a><b>1. 集群搭建</b></h2><p>搭建一个 2 replica 测试集群，由于条件有限，这里在同一台物理机上起 clickhouse-server(2个 replica) + zookeeper(1个)，为了避免端口冲突，两个 replica 端口会有所不同。</p><h3 id="1-1-zookeeper"><a href="#1-1-zookeeper" class="headerlink" title="1.1 zookeeper"></a><b>1.1 zookeeper</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run  -p 2181:2181 --name some-zookeeper --restart always -d zookeeper</span><br></pre></td></tr></table></figure><h3 id="1-2-replica集群"><a href="#1-2-replica集群" class="headerlink" title="1.2 replica集群"></a><b>1.2 replica集群</b></h3><p>replica-1 config.xml:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;zookeeper&gt;</span><br><span class="line">   &lt;node index=&quot;1&quot;&gt;</span><br><span class="line">      &lt;host&gt;172.17.0.2&lt;/host&gt;</span><br><span class="line">      &lt;port&gt;2181&lt;/port&gt;</span><br><span class="line">   &lt;/node&gt;</span><br><span class="line">&lt;/zookeeper&gt;</span><br><span class="line"></span><br><span class="line">&lt;remote_servers&gt;</span><br><span class="line">   &lt;mycluster_1&gt;</span><br><span class="line">      &lt;shard_1&gt;</span><br><span class="line">         &lt;internal_replication&gt;true&lt;/internal_replication&gt;</span><br><span class="line">         &lt;replica&gt;</span><br><span class="line">            &lt;host&gt;s1&lt;/host&gt;</span><br><span class="line">            &lt;port&gt;9000&lt;/port&gt;</span><br><span class="line">         &lt;/replica&gt;</span><br><span class="line">         &lt;replica&gt;</span><br><span class="line">            &lt;host&gt;s2&lt;/host&gt;</span><br><span class="line">            &lt;port&gt;9001&lt;/port&gt;</span><br><span class="line">         &lt;/replica&gt;</span><br><span class="line">      &lt;/shard_1&gt;</span><br><span class="line">   &lt;/mycluster_1&gt;</span><br><span class="line">&lt;/remote_servers&gt;</span><br><span class="line"></span><br><span class="line">&lt;macros&gt;</span><br><span class="line">   &lt;cluster&gt;mycluster_1&lt;/cluster&gt;</span><br><span class="line">   &lt;shard&gt;1&lt;/shard&gt;</span><br><span class="line">   &lt;replica&gt;s1&lt;/replica&gt;</span><br><span class="line">&lt;/macros&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;tcp_port&gt;9101&lt;/tcp_port&gt;</span><br><span class="line">&lt;interserver_http_port&gt;9009&lt;/interserver_http_port&gt;</span><br><span class="line">&lt;path&gt;/cluster/d1/datas/&lt;/path&gt;</span><br></pre></td></tr></table></figure><p>replica-2 config.xml:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;zookeeper&gt;</span><br><span class="line">   &lt;node index=&quot;1&quot;&gt;</span><br><span class="line">      &lt;host&gt;172.17.0.2&lt;/host&gt;</span><br><span class="line">      &lt;port&gt;2181&lt;/port&gt;</span><br><span class="line">   &lt;/node&gt;</span><br><span class="line">&lt;/zookeeper&gt;</span><br><span class="line"></span><br><span class="line">&lt;remote_servers&gt;</span><br><span class="line">   &lt;mycluster_1&gt;</span><br><span class="line">      &lt;shard_1&gt;</span><br><span class="line">         &lt;internal_replication&gt;true&lt;/internal_replication&gt;</span><br><span class="line">         &lt;replica&gt;</span><br><span class="line">            &lt;host&gt;s1&lt;/host&gt;</span><br><span class="line">            &lt;port&gt;9000&lt;/port&gt;</span><br><span class="line">         &lt;/replica&gt;</span><br><span class="line">         &lt;replica&gt;</span><br><span class="line">            &lt;host&gt;s2&lt;/host&gt;</span><br><span class="line">            &lt;port&gt;9001&lt;/port&gt;</span><br><span class="line">         &lt;/replica&gt;</span><br><span class="line">      &lt;/shard_1&gt;</span><br><span class="line">   &lt;/mycluster_1&gt;</span><br><span class="line">&lt;/remote_servers&gt;</span><br><span class="line"></span><br><span class="line">&lt;macros&gt;</span><br><span class="line">   &lt;cluster&gt;mycluster_1&lt;/cluster&gt;</span><br><span class="line">   &lt;shard&gt;1&lt;/shard&gt;</span><br><span class="line">   &lt;replica&gt;s2&lt;/replica&gt;</span><br><span class="line">&lt;/macros&gt;</span><br><span class="line"></span><br><span class="line">&lt;tcp_port&gt;9102&lt;/tcp_port&gt;</span><br><span class="line">&lt;interserver_http_port&gt;9010&lt;/interserver_http_port&gt;</span><br><span class="line">&lt;path&gt;/cluster/d2/datas/&lt;/path&gt;</span><br></pre></td></tr></table></figure><h3 id="1-3-创建测试表"><a href="#1-3-创建测试表" class="headerlink" title="1.3 创建测试表"></a><b>1.3 创建测试表</b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE default.rtest1 ON CLUSTER &#x27;mycluster_1&#x27;</span><br><span class="line">(</span><br><span class="line">    `id` Int64,</span><br><span class="line">    `p` Int16</span><br><span class="line">)</span><br><span class="line">ENGINE = ReplicatedMergeTree(&#x27;/clickhouse/tables/replicated/test&#x27;, &#x27;&#123;replica&#125;&#x27;)</span><br><span class="line">PARTITION BY p</span><br><span class="line">ORDER BY id</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="1-4-查看-zookeeper"><a href="#1-4-查看-zookeeper" class="headerlink" title=" 1.4 查看 zookeeper "></a><b> 1.4 查看 zookeeper </b></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it some-zookeeper bash</span><br><span class="line">./bin/zkCli.sh</span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 17] ls /clickhouse/tables/replicated/test/replicas</span><br><span class="line">[s1, s2]</span><br></pre></td></tr></table></figure><p>两个 replica 都已经注册到 zookeeper。</p><h2 id="2-同步原理"><a href="#2-同步原理" class="headerlink" title=" 2. 同步原理 "></a><b> 2. 同步原理 </b></h2><p>如果在 replica-1 上执行了一条写入:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replica-1&gt; INSERT INTO rtest VALUES(33,33);</span><br></pre></td></tr></table></figure><p>数据是如何同步到 replica-2 的呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">s1.  replica-1&gt; StorageReplicatedMergeTree::write --&gt; ReplicatedMergeTreeBlockOutputStream::write(const Block &amp; block)</span><br><span class="line">s2.  replica-1&gt; storage.writer.writeTempPart，写入本地磁盘</span><br><span class="line">s3.  replica-1&gt; ReplicatedMergeTreeBlockOutputStream::commitPart</span><br><span class="line">s4.  replica-1&gt; StorageReplicatedMergeTree::getCommitPartOp，提交LogEntry到zookeeper，信息包括:</span><br><span class="line">    ReplicatedMergeTreeLogEntry &#123;</span><br><span class="line">     type: GET_PART,</span><br><span class="line">     source_replica: replica-1,</span><br><span class="line">     new_part_name: part-&gt;name,</span><br><span class="line">     new_part_type: part-&gt;getType</span><br><span class="line">    &#125;</span><br><span class="line">s5.  replica-1&gt; zkutil::makeCreateRequest(zookeeper_path + &quot;/log/log-0000000022&quot;)，更新log_pointer到zookeeper</span><br><span class="line"></span><br><span class="line">s6.  replica-2&gt; StorageReplicatedMergeTree::queueUpdatingTask()，定时pull任务</span><br><span class="line">s7.  replica-2&gt; ReplicatedMergeTreeQueue::pullLogsToQueue ，拉取</span><br><span class="line">s8.  replica-2&gt; zookeeper-&gt;get(replica_path + &quot;/log_pointer&quot;) ，向zookeeper获取当前replica已经同步的位点</span><br><span class="line">s9.  replica-2&gt; zookeeper-&gt;getChildrenWatch(zookeeper_path + &quot;/log&quot;) ，向zookeeper获取所有的LogEntry信息</span><br><span class="line">s10. replica-2&gt; 根据同步位点log_pointer从所有LogEntry中筛选需要同步的LogEntry，写到queue</span><br><span class="line">s11. replica-2&gt; StorageReplicatedMergeTree::queueTask，消费queue任务</span><br><span class="line">s12. replica-2&gt; StorageReplicatedMergeTree::executeLogEntry(LogEntry &amp; entry)，根据LogEntry type执行消费</span><br><span class="line">s13. replica-2&gt; StorageReplicatedMergeTree::executeFetch(LogEntry &amp; entry) </span><br><span class="line">s14. replica-2&gt; StorageReplicatedMergeTree::fetchPart，从replica-1的interserver_http_port下载part目录数据</span><br><span class="line">s15. replica-2&gt; MergeTreeData::renameTempPartAndReplace，把文件写入本地并更新内存meta信息</span><br><span class="line">s16. replica-2&gt; 数据同步完成</span><br></pre></td></tr></table></figure><p>也可以进入 zookeeper docker 内部直接查看某个 LogEntry:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 85] get /clickhouse/tables/replicated/test/log/log-0000000022</span><br><span class="line">format version: 4</span><br><span class="line">create_time: 2020-09-13 16:39:05</span><br><span class="line">source replica: s1</span><br><span class="line">block_id: 33_2673203974107464807_7670041793554220344</span><br><span class="line">get</span><br><span class="line">33_2_2_0</span><br></pre></td></tr></table></figure><h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a><b>3. 总结</b></h2><p>本文以写入为例，从底层分析了 ClickHouse ReplicatedMergeTree 的工作原理，逻辑并不复杂。</p><p>不同 replica 的数据同步需要 zookeeper(目前社区有人在做etcd的集成 <a href="https://github.com/ClickHouse/ClickHouse/pull/10376">pr#10376</a>)做元数据协调，是一个订阅&#x2F;消费模型，涉及具体数据目录还需要去相应的 replica 通过 interserver_http_port 端口进行下载。</p><p>replica 的同步都是以文件目录为单位，这样就带来一个好处：我们<b>可以轻松实现 ClickHouse 的存储计算分离</b>，多个 clickhouse-server 可以同时挂载同一份数据进行计算，而且这些 server 每个节点都是可写，虎哥已经实现了一个可以 work 的原型，详情请参考下篇 <a href="/2020/09/18/clickhouse-and-friends-compute-storage/">&lt;存储计算分离方案与实现&gt;</a>。</p><h2 id="4-参考"><a href="#4-参考" class="headerlink" title="4. 参考"></a><b>4. 参考</b></h2><p>[1]  <a href="https://github.com/ClickHouse/ClickHouse/blob/f37814b36754bf11b52bd9c77d0e15f4d1825033/src/Storages/StorageReplicatedMergeTree.cpp">StorageReplicatedMergeTree.cpp</a><br>[2] <a href="https://github.com/ClickHouse/ClickHouse/blob/f37814b36754bf11b52bd9c77d0e15f4d1825033/src/Storages/MergeTree/ReplicatedMergeTreeBlockOutputStream.cpp">ReplicatedMergeTreeBlockOutputStream.cpp</a><br>[3] <a href="https://github.com/ClickHouse/ClickHouse/blob/f37814b36754bf11b52bd9c77d0e15f4d1825033/src/Storages/MergeTree/ReplicatedMergeTreeLogEntry.cpp">ReplicatedMergeTreeLogEntry.cpp</a><br>[4] <a href="https://github.com/ClickHouse/ClickHouse/blob/f37814b36754bf11b52bd9c77d0e15f4d1825033/src/Storages/MergeTree/ReplicatedMergeTreeQueue.cpp">ReplicatedMergeTreeQueue.cpp</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;img src=&quot;https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-replicatedmergetree.png&quot; align=&quot;center&quot; style=&quot;z</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="replicatedmergetree" scheme="https://bohutang.me/tags/replicatedmergetree/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
    <category term="zookeeper" scheme="https://bohutang.me/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（12）神奇的物化视图(Materialized View)与原理</title>
    <link href="https://bohutang.me/2020/08/31/clickhouse-and-friends-materialized-view/"/>
    <id>https://bohutang.me/2020/08/31/clickhouse-and-friends-materialized-view/</id>
    <published>2020-08-30T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.051Z</updated>
    
    <content type="html"><![CDATA[<img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-materializeview.png" align="center" style="zoom:50%;" /><p><b>最后更新: 2020-08-31</b></p><p>在 ClickHouse 里，物化视图(Materialized View)可以说是一个神奇且强大的东西，用途别具一格。</p><p>本文从底层机制进行分析，看看 ClickHouse 的 Materalized View 是怎么工作的，以方便更好的使用它。</p><h2 id="什么是物化视图"><a href="#什么是物化视图" class="headerlink" title="什么是物化视图"></a><b>什么是物化视图</b></h2><p>对大部分人来说，物化视图这个概念会比较抽象，物化？视图？。。。</p><p>为了更好的理解它，我们先看一个场景。</p><p>假设你是 *hub 一个“幸福”的小程序员，某天产品经理有个需求：实时统计每小时视频下载量。</p><p>用户下载明细表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT * FROM download LIMIT 10;</span><br><span class="line">+---------------------+--------+--------+</span><br><span class="line">| when                | userid | bytes  |</span><br><span class="line">+---------------------+--------+--------+</span><br><span class="line">| 2020-08-31 18:22:06 |     19 | 530314 |</span><br><span class="line">| 2020-08-31 18:22:06 |     19 | 872957 |</span><br><span class="line">| 2020-08-31 18:22:06 |     19 | 107047 |</span><br><span class="line">| 2020-08-31 18:22:07 |     19 | 214876 |</span><br><span class="line">| 2020-08-31 18:22:07 |     19 | 820943 |</span><br><span class="line">| 2020-08-31 18:22:07 |     19 | 693959 |</span><br><span class="line">| 2020-08-31 18:22:08 |     19 | 882151 |</span><br><span class="line">| 2020-08-31 18:22:08 |     19 | 644223 |</span><br><span class="line">| 2020-08-31 18:22:08 |     19 | 199800 |</span><br><span class="line">| 2020-08-31 18:22:09 |     19 | 511439 |</span><br><span class="line"></span><br><span class="line">... ....</span><br></pre></td></tr></table></figure><p>计算每小时下载量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT toStartOfHour(when) AS hour, userid, count() as downloads, sum(bytes) AS bytes FROM download GROUP BY userid, hour ORDER BY userid, hour;</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| hour                | userid | downloads | bytes      |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| 2020-08-31 18:00:00 |     19 |      6822 | 3378623036 |</span><br><span class="line">| 2020-08-31 19:00:00 |     19 |     10800 | 5424173178 |</span><br><span class="line">| 2020-08-31 20:00:00 |     19 |     10800 | 5418656068 |</span><br><span class="line">| 2020-08-31 21:00:00 |     19 |     10800 | 5404309443 |</span><br><span class="line">| 2020-08-31 22:00:00 |     19 |     10800 | 5354077456 |</span><br><span class="line">| 2020-08-31 23:00:00 |     19 |     10800 | 5390852563 |</span><br><span class="line">| 2020-09-01 00:00:00 |     19 |     10800 | 5369839540 |</span><br><span class="line">| 2020-09-01 01:00:00 |     19 |     10800 | 5384161012 |</span><br><span class="line">| 2020-09-01 02:00:00 |     19 |     10800 | 5404581759 |</span><br><span class="line">| 2020-09-01 03:00:00 |     19 |      6778 | 3399557322 |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">10 rows in set (0.13 sec)</span><br></pre></td></tr></table></figure><p>很容易嘛，不过有个问题：<br>每次都要以 <code>download</code> 表为基础数据进行计算，*hub 数据量太大，无法忍受。</p><p>想到一个办法：如果对 <code>download</code> 进行预聚合，把结果保存到一个新表 <code>download_hour_mv</code>，并随着 <code>download</code> 增量实时更新，每次去查询<code>download_hour_mv</code> 不就可以了。</p><p>这个新表可以看做是一个物化视图，它在 ClickHouse 是一个普通表。</p><h2 id="创建物化视图"><a href="#创建物化视图" class="headerlink" title="创建物化视图"></a><b>创建物化视图</b></h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; CREATE MATERIALIZED VIEW download_hour_mv</span><br><span class="line">ENGINE = SummingMergeTree</span><br><span class="line">PARTITION BY toYYYYMM(hour) ORDER BY (userid, hour)</span><br><span class="line">AS SELECT</span><br><span class="line">  toStartOfHour(when) AS hour,</span><br><span class="line">  userid,</span><br><span class="line">  count() as downloads,</span><br><span class="line">  sum(bytes) AS bytes</span><br><span class="line">FROM download WHERE when &gt;= toDateTime(&#x27;2020-09-01 04:00:00&#x27;)</span><br><span class="line">GROUP BY userid, hour</span><br></pre></td></tr></table></figure><p>这个语句主要做了：</p><ul><li>创建一个引擎为 <code>SummingMergeTree</code> 的物化视图 <code>download_hour_mv</code></li><li>物化视图的数据来源于 <code>download</code> 表，并根据 <code>select</code> 语句中的表达式进行相应“物化”操作</li><li>选取一个未来时间(当前时间是 <code>2020-08-31 18:00:00</code>)作为开始点 <code>WHERE when &gt;= toDateTime(&#39;2020-09-01 04:00:00&#39;)</code>，表示在<code>2020-09-01 04:00:00</code> 之后的数据才会被同步到 <code>download_hour_mv</code></li></ul><p>这样，目前 <code>download_hour_mv</code> 是一个空表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT * FROM download_hour_mv ORDER BY userid, hour;</span><br><span class="line">Empty set (0.02 sec)</span><br></pre></td></tr></table></figure><p>注意：官方有 <a href="https://clickhouse.tech/docs/en/sql-reference/statements/create/view/#materialized">POPULATE</a> 关键字，但是不建议使用，因为视图创建期间 <code>download</code> 如果有写入数据会丢失，这也是我们加一个 <code>WHERE</code> 作为数据同步点的原因。</p><p>那么，我们如何让源表数据可以一致性的同步到 <code>download_hour_mv</code> 呢？</p><h2 id="物化全量数据"><a href="#物化全量数据" class="headerlink" title="物化全量数据"></a><b>物化全量数据</b></h2><p>在<code>2020-09-01 04:00:00</code>之后，我们可以通过一个带 <code>WHERE</code> 快照的<code>INSERT INTO SELECT...</code> 对 <code>download</code> 历史数据进行物化：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; INSERT INTO download_hour_mv</span><br><span class="line">SELECT</span><br><span class="line">  toStartOfHour(when) AS hour,</span><br><span class="line">  userid,</span><br><span class="line">  count() as downloads,</span><br><span class="line">  sum(bytes) AS bytes</span><br><span class="line">FROM download WHERE when &lt; toDateTime(&#x27;2020-09-01 04:00:00&#x27;)</span><br><span class="line">GROUP BY userid, hour</span><br></pre></td></tr></table></figure><p>查询物化视图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT * FROM download_hour_mv ORDER BY hour, userid, downloads DESC;</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| hour                | userid | downloads | bytes      |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| 2020-08-31 18:00:00 |     19 |      6822 | 3378623036 |</span><br><span class="line">| 2020-08-31 19:00:00 |     19 |     10800 | 5424173178 |</span><br><span class="line">| 2020-08-31 20:00:00 |     19 |     10800 | 5418656068 |</span><br><span class="line">| 2020-08-31 21:00:00 |     19 |     10800 | 5404309443 |</span><br><span class="line">| 2020-08-31 22:00:00 |     19 |     10800 | 5354077456 |</span><br><span class="line">| 2020-08-31 23:00:00 |     19 |     10800 | 5390852563 |</span><br><span class="line">| 2020-09-01 00:00:00 |     19 |     10800 | 5369839540 |</span><br><span class="line">| 2020-09-01 01:00:00 |     19 |     10800 | 5384161012 |</span><br><span class="line">| 2020-09-01 02:00:00 |     19 |     10800 | 5404581759 |</span><br><span class="line">| 2020-09-01 03:00:00 |     19 |      6778 | 3399557322 |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">10 rows in set (0.05 sec)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到数据已经“物化”到 <code>download_hour_mv</code>。</p><h2 id="物化增量数据"><a href="#物化增量数据" class="headerlink" title="物化增量数据"></a><b>物化增量数据</b></h2><p>写一些数据到 <code>download</code>表:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; INSERT INTO download</span><br><span class="line">       SELECT</span><br><span class="line">         toDateTime(&#x27;2020-09-01 04:00:00&#x27;) + number*(1/3) as when,</span><br><span class="line">         19,</span><br><span class="line">         rand() % 1000000</span><br><span class="line">       FROM system.numbers</span><br><span class="line">       LIMIT 10;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>查询物化视图 <code>download_hour_mv</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT * FROM download_hour_mv ORDER BY hour, userid, downloads;</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| hour                | userid | downloads | bytes      |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">| 2020-08-31 18:00:00 |     19 |      6822 | 3378623036 |</span><br><span class="line">| 2020-08-31 19:00:00 |     19 |     10800 | 5424173178 |</span><br><span class="line">| 2020-08-31 20:00:00 |     19 |     10800 | 5418656068 |</span><br><span class="line">| 2020-08-31 21:00:00 |     19 |     10800 | 5404309443 |</span><br><span class="line">| 2020-08-31 22:00:00 |     19 |     10800 | 5354077456 |</span><br><span class="line">| 2020-08-31 23:00:00 |     19 |     10800 | 5390852563 |</span><br><span class="line">| 2020-09-01 00:00:00 |     19 |     10800 | 5369839540 |</span><br><span class="line">| 2020-09-01 01:00:00 |     19 |     10800 | 5384161012 |</span><br><span class="line">| 2020-09-01 02:00:00 |     19 |     10800 | 5404581759 |</span><br><span class="line">| 2020-09-01 03:00:00 |     19 |      6778 | 3399557322 |</span><br><span class="line">| 2020-09-01 04:00:00 |     19 |        10 |    5732600 |</span><br><span class="line">+---------------------+--------+-----------+------------+</span><br><span class="line">11 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>可以看到最后一条数据就是我们增量的一个物化聚合，已经实时同步，这是如何做到的呢？</p><h2 id="物化视图原理"><a href="#物化视图原理" class="headerlink" title="物化视图原理"></a><b>物化视图原理</b></h2><p>ClickHouse 的物化视图原理并不复杂，在 <code>download</code> 表有新的数据写入时，如果检测到有物化视图跟它关联，会针对这批写入的数据进行物化操作。</p><p>比如上面新增数据是通过以下 SQL 生成的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">clickhouse&gt; SELECT</span><br><span class="line">    -&gt;          toDateTime(&#x27;2020-09-01 04:00:00&#x27;) + number*(1/3) as when,</span><br><span class="line">    -&gt;          19,</span><br><span class="line">    -&gt;          rand() % 1000000</span><br><span class="line">    -&gt;        FROM system.numbers</span><br><span class="line">    -&gt;        LIMIT 10;</span><br><span class="line">+---------------------+------+-------------------------+</span><br><span class="line">| when                | 19   | modulo(rand(), 1000000) |</span><br><span class="line">+---------------------+------+-------------------------+</span><br><span class="line">| 2020-09-01 04:00:00 |   19 |                  870495 |</span><br><span class="line">| 2020-09-01 04:00:00 |   19 |                  322270 |</span><br><span class="line">| 2020-09-01 04:00:00 |   19 |                  983422 |</span><br><span class="line">| 2020-09-01 04:00:01 |   19 |                  759708 |</span><br><span class="line">| 2020-09-01 04:00:01 |   19 |                  975636 |</span><br><span class="line">| 2020-09-01 04:00:01 |   19 |                  365507 |</span><br><span class="line">| 2020-09-01 04:00:02 |   19 |                  865569 |</span><br><span class="line">| 2020-09-01 04:00:02 |   19 |                  975742 |</span><br><span class="line">| 2020-09-01 04:00:02 |   19 |                   85827 |</span><br><span class="line">| 2020-09-01 04:00:03 |   19 |                  992779 |</span><br><span class="line">+---------------------+------+-------------------------+</span><br><span class="line">10 rows in set (0.02 sec)</span><br></pre></td></tr></table></figure><p>物化视图执行的语句类似：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO download_hour_mv</span><br><span class="line">SELECT</span><br><span class="line">  toStartOfHour(when) AS hour,</span><br><span class="line">  userid,</span><br><span class="line">  count() as downloads,</span><br><span class="line">  sum(bytes) AS bytes</span><br><span class="line">FROM [新增的10条数据] WHERE when &gt;= toDateTime(&#x27;2020-09-01 04:00:00&#x27;)</span><br><span class="line">GROUP BY userid, hour</span><br></pre></td></tr></table></figure><p>代码导航：</p><ol><li><p>添加视图 OutputStream， <a href="https://github.com/ClickHouse/ClickHouse/blob/cb4644ea6d04b3d5900868b4f8d686a03082379a/src/Interpreters/InterpreterInsertQuery.cpp#L313">InterpreterInsertQuery.cpp</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (table-&gt;noPushingToViews() &amp;&amp; !no_destination)</span><br><span class="line">    out = table-&gt;write(query_ptr, metadata_snapshot, context);</span><br><span class="line">else</span><br><span class="line">    out = std::make_shared&lt;PushingToViewsBlockOutputStream&gt;(table, metadata_snapshot, context, query_ptr, no_destination);</span><br></pre></td></tr></table></figure></li><li><p>构造 Insert ， <a href="https://github.com/ClickHouse/ClickHouse/blob/cb4644ea6d04b3d5900868b4f8d686a03082379a/src/DataStreams/PushingToViewsBlockOutputStream.cpp#L85">PushingToViewsBlockOutputStream.cpp</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ASTPtr insert_query_ptr(insert.release());</span><br><span class="line">InterpreterInsertQuery interpreter(insert_query_ptr, *insert_context);</span><br><span class="line">BlockIO io = interpreter.execute();</span><br><span class="line">out = io.out;</span><br></pre></td></tr></table></figure></li><li><p>物化新增数据：<a href="https://github.com/ClickHouse/ClickHouse/blob/cb4644ea6d04b3d5900868b4f8d686a03082379a/src/DataStreams/PushingToViewsBlockOutputStream.cpp#L331">PushingToViewsBlockOutputStream.cpp</a></p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Context local_context = *select_context;</span><br><span class="line">local_context.addViewSource(</span><br><span class="line">    StorageValues::create(</span><br><span class="line">        storage-&gt;getStorageID(), metadata_snapshot-&gt;getColumns(), block, storage-&gt;getVirtuals()));</span><br><span class="line">select.emplace(view.query, local_context, SelectQueryOptions());</span><br><span class="line">in = std::make_shared&lt;MaterializingBlockInputStream&gt;(select-&gt;execute().getInputStream()</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p>物化视图的用途较多。</p><p>比如可以解决表索引问题，我们可以用物化视图创建另外一种物理序，来满足某些条件下的查询问题。</p><p>还有就是通过物化视图的实时同步数据能力，我们可以做到更加灵活的表结构变更。</p><p>更强大的地方是它可以借助 MergeTree 家族引擎(SummingMergeTree、Aggregatingmergetree等)，得到一个实时的预聚合，满足快速查询。</p><p>原理是把增量的数据根据 <code>AS SELECT ...</code> 对其进行处理并写入到物化视图表，物化视图是一种普通表，可以直接读取和写入。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;img src=&quot;https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-materializeview.png&quot; align=&quot;center&quot; style=&quot;zoom:</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
    <category term="materialized view" scheme="https://bohutang.me/tags/materialized-view/"/>
    
    <category term="物化视图" scheme="https://bohutang.me/tags/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（11）MySQL实时复制之GTID模式</title>
    <link href="https://bohutang.me/2020/08/26/clickhouse-and-friends-mysql-gtid-replication/"/>
    <id>https://bohutang.me/2020/08/26/clickhouse-and-friends-mysql-gtid-replication/</id>
    <published>2020-08-25T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.051Z</updated>
    
    <content type="html"><![CDATA[<img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-materialzemysql.png" align="center" style="zoom:50%;" /><p><b>最后更新: 2020-09-03</b></p><p> <a href="/2020/07/26/clickhouse-and-friends-mysql-replication/">MySQL实时复制原理篇</a></p><p>几天前 ClickHouse 官方发布了 <a href="https://github.com/ClickHouse/ClickHouse/releases/tag/v20.8.1.4447-testing">v20.8.1.4447-testing</a>，这个版本已经包含了 MaterializeMySQL 引擎，实现了 ClickHouse 实时复制 MySQL 数据的能力，感兴趣的朋友可以通过官方安装包来做体验，安装方式参考: <a href="https://clickhouse.tech/#quick-start">https://clickhouse.tech/#quick-start</a>，需要注意的是要选择 testing 分支。</p><h2 id="基于位点同步"><a href="#基于位点同步" class="headerlink" title="基于位点同步"></a><b>基于位点同步</b></h2><p>MaterializeMySQL 在 v20.8.1.4447-testing 版本是基于 binlog 位点模式进行同步的。</p><p>每次消费完一批 binlog event，就会记录 event 的位点信息到 .metadata 文件:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Version:1</span><br><span class="line">Binlog File:mysql-bin.000002</span><br><span class="line">Binlog Position:328</span><br><span class="line">Data Version:1</span><br></pre></td></tr></table></figure><p>这样当 ClickHouse 再次启动时，它会把 {‘mysql-bin.000002’, 328} 二元组通过协议告知 MySQL Server，MySQL 从这个位点开始发送数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s1&gt; ClickHouse 发送 &#123;&#x27;mysql-bin.000002&#x27;, 328&#125; 位点信息给 MySQL</span><br><span class="line">s2&gt; MySQL 找到本地 mysql-bin.000002 文件并定位到 328 偏移位置，读取下一个 event 发送给 ClickHouse</span><br><span class="line">s3&gt; ClickHouse 接收 binlog event 并更新 .metadata位点</span><br></pre></td></tr></table></figure><p>看起来不错哦，但是有个问题：<br>如果 MySQL Server 是一个集群(比如１主２从)，通过 VIP 对外服务，MaterializeMySQL 的 host 指向的是这个 vip。<br>当集群主从发生切换后，{binlog-name, binlog-position} 二元组其实是不准确的，因为集群里主从 binlog 不一定是完全一致的(binlog 可以做 reset 操作)。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s1&gt; ClickHouse 发送 &#123;&#x27;mysql-bin.000002&#x27;, 328&#125; 给集群新主 MySQL</span><br><span class="line">s2&gt; 新主 MySQL 发现本地没有 mysql-bin.000002 文件，因为它做过 reset master 操作，binlog 文件是 mysql-bin.000001</span><br><span class="line">... oops ...</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为了解决这个问题，我们开发了 GTID 同步模式，废弃了不安全的位点同步模式，目前已被 upstream merged <a href="https://github.com/ClickHouse/ClickHouse/pull/13820">#PR13820</a>，下一个 testing 版本即可体验。</p><p>着急的话可以自己编译或通过 <a href="https://clickhouse-builds.s3.yandex.net/0/2b8ad576cc3892d2d760f3f8b670adf17db0c2a0/clickhouse_build_check/report.html">ClickHouse Build Check for master-20.9.1</a> 下载安装。</p><h2 id="基于GTID同步"><a href="#基于GTID同步" class="headerlink" title="基于GTID同步"></a><b>基于GTID同步</b></h2><p>GTID 是 MySQL 复制增强版，从 MySQL 5.6 版本开始支持，目前已经是 MySQL 主流复制模式。</p><p>它为每个 event 分配一个全局唯一ID和序号，我们可以不用关心 MySQL 集群主从拓扑结构，直接告知 MySQL 这个 GTID 即可，.metadata变为:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Version:2</span><br><span class="line">Executed GTID:f4aee41e-e36f-11ea-8b37-0242ac110002:1-5</span><br><span class="line">Data Version:1</span><br></pre></td></tr></table></figure><p><code>f4aee41e-e36f-11ea-8b37-0242ac110002</code> 是生成 event的主机UUID，<code>1-5</code>是已经同步的event区间。</p><p>这样流程就变为:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s1&gt; ClickHouse 发送 GTID:f4aee41e-e36f-11ea-8b37-0242ac110002:1-5 给 MySQL</span><br><span class="line">s2&gt; MySQL 根据 GTID:f4aee41e-e36f-11ea-8b37-0242ac110002:1-5 找到本地位点，读取下一个 event 发送给 ClickHouse</span><br><span class="line">s3&gt; ClickHouse 接收 binlog event 并更新 .metadata GTID信息</span><br></pre></td></tr></table></figure><h2 id="MySQL开启GTID"><a href="#MySQL开启GTID" class="headerlink" title=" MySQL开启GTID"></a><b> MySQL开启GTID</b></h2><p>那么，MySQL 侧怎么开启 GTID 呢？增加以下两个参数即可:</p><p><code>--gtid-mode=ON --enforce-gtid-consistency</code></p><p>比如启动一个启用 GTID 的 MySQL docker：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -e MYSQL_ROOT_PASSWORD=123 mysql:5.7 mysqld --datadir=/var/lib/mysql --server-id=1 --log-bin=/var/lib/mysql/mysql-bin.log --gtid-mode=ON --enforce-gtid-consistency</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a><b>注意事项</b></h2><p>启用 GTID 复制模式后，metadata Version 会变为 2，也就是老版本启动时会直接报错，database 需要重建。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p>MaterializeMySQL 引擎还处于不停迭代中，对于它我们有一个初步的规划：</p><ul><li><p><b>稳定性保证</b><br>这块需要更多测试，更多试用反馈</p></li><li><p><b>索引优化</b><br>OLTP 索引一般不是为 OLAP 设计，目前索引转换还是依赖 MySQL 表结构，需要更加智能化</p></li><li><p><b>可观测性</b><br>在 ClickHouse 侧可以方便的查看当前同步信息，类似 MySQL <code>show slave status</code></p></li><li><p><b>数据一致性校验</b><br>需要提供方式可以校验 MySQL 和 ClickHouse 数据一致性</p></li></ul><p>MaterializeMySQL 已经是社区功能，仍然有不少的工作要做。期待更多的力量加入，我们的征途不止星辰大海。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;img src=&quot;https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/clickhouse-map-2020-materialzemysql.png&quot; align=&quot;center&quot; style=&quot;zoom:</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
    <category term="MySQL" scheme="https://bohutang.me/tags/MySQL/"/>
    
    <category term="replication" scheme="https://bohutang.me/tags/replication/"/>
    
    <category term="GTID" scheme="https://bohutang.me/tags/GTID/"/>
    
  </entry>
  
  <entry>
    <title>ClickHouse和他的朋友们（10）MergeTree Write-Ahead Log</title>
    <link href="https://bohutang.me/2020/08/18/clickhouse-and-friends-merge-tree-wal/"/>
    <id>https://bohutang.me/2020/08/18/clickhouse-and-friends-merge-tree-wal/</id>
    <published>2020-08-17T16:00:00.000Z</published>
    <updated>2022-08-27T08:25:55.051Z</updated>
    
    <content type="html"><![CDATA[<p><b>最后更新: 2020-09-18</b></p><p>数据库系统为了提高写入性能，会把数据先写到内存，等“攒”到一定程度后再回写到磁盘，比如 MySQL 的 buffer pool 机制。</p><p>因为数据先写到内存，为了数据的安全性，我们需要一个 Write-Ahead Log (WAL) 来保证内存数据的安全性。</p><p>今天我们来看看 ClickHouse 新增的 <a href="https://github.com/ClickHouse/ClickHouse/pull/8290">MergeTreeWriteAheadLog</a> 模块，它到底解决了什么问题。</p><h2 id="高频写问题"><a href="#高频写问题" class="headerlink" title="高频写问题"></a><b>高频写问题</b></h2><p>对于 ClickHouse MergeTree 引擎，每次写入(即使１条数据)都会在磁盘生成一个分区目录(part)，等着 merge 线程合并。</p><p>如果有多个客户端，每个客户端写入的数据量较少、次数较频繁的情况下，就会引发 <code>DB::Exception: Too many parts</code> 错误。</p><p>这样就对客户端有一定的要求，比如需要做 batch 写入。</p><p>或者，写入到 Buffer 引擎，定时的刷回 MergeTree，缺点是在宕机时可能会丢失数据。</p><h2 id="MergeTree-WAL"><a href="#MergeTree-WAL" class="headerlink" title="MergeTree WAL"></a><b>MergeTree WAL</b></h2><h3 id="1-默认模式"><a href="#1-默认模式" class="headerlink" title="1. 默认模式"></a><b>1. 默认模式</b></h3><p>我们先看看在没有 WAL 情况下，MergeTree 是如何写入的：</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/mergetree-part-raw.png" align="center" style="zoom:50%;" /><p>每次写入 MergeTree 都会直接在磁盘上创建分区目录，并生成分区数据，这种模式其实就是 WAL + 数据的融合。</p><p>很显然，这种模式不适合频繁写操作的情况，否则会生成非常多的分区目录和文件，引发 <code>Too many parts</code> 错误。</p><h3 id="2-WAL模式"><a href="#2-WAL模式" class="headerlink" title="2. WAL模式"></a><b>2. WAL模式</b></h3><p>设置SETTINGS: <code>min_rows_for_compact_part=2</code>，分别执行２条写 SQL，数据会先写到 wal.bin 文件：</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/mergetree-part-wal.png" align="center" style="zoom:50%;" /><p>当满足  <code>min_rows_for_compact_part=2</code> 后，merger 线程触发合并操作，生成  <code>1_1_2_1</code> 分区，也就是完成了 wal.bin 里的 <code>1_1_1_0</code> 和 <code>1_2_2_0</code> 两个分区的合并操作。当我们执行第三条 SQL 写入:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">insert into default.mt(a,b,c) values(1,3,3)</span><br></pre></td></tr></table></figure><p>数据块(分区)会继续追加到 wal.bin 尾部：</p><img src="https://bohutang-1253727613.cos.ap-beijing.myqcloud.com/posts/mergetree-part-wal-merge.png" align="center" style="zoom:50%;" /><p>此时，3 条数据分布在两个地方：分区 <code>1_1_2_1</code>， wal.bin 里的 <code>1_3_3_0</code>。</p><p>这样就有一个问题：当我们执行查询的时候，数据是怎么合并的呢？</p><p>MergeTree 使用全局结构 <code>data_parts_indexes</code> 维护分区信息，当服务启动的时候，<code> MergeTreeData::loadDataParts</code>方法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. data_parts_indexes.insert(1_1_2_1)</span><br><span class="line">2. 读取 wal.bin，通过 getActiveContainingPart 判断分区是否已经merge到磁盘：1_1_1_0 已经存在, 1_2_2_0 已经存在，data_parts_indexes.insert(1_3_3_0)</span><br><span class="line">3. data_parts_indexes:&#123;1_1_2_1,1_3_3_0&#125; </span><br></pre></td></tr></table></figure><p>这样，它总是能维护全局的分区信息。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h2><p>WAL 功能在 <a href="https://github.com/ClickHouse/ClickHouse/pull/8290">PR＃8290</a> 实现，master 分支已经默认开启。</p><p>MergeTree 通过 WAL 来保护客户端的高频、少量写机制，减少服务端目录和文件数量，让客户端操作尽可能简单、高效。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;b&gt;最后更新: 2020-09-18&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;数据库系统为了提高写入性能，会把数据先写到内存，等“攒”到一定程度后再回写到磁盘，比如 MySQL 的 buffer pool 机制。&lt;/p&gt;
&lt;p&gt;因为数据先写到内存，为了数据的安全性，我们需要一个 Write</summary>
      
    
    
    
    
    <category term="clickhouse" scheme="https://bohutang.me/tags/clickhouse/"/>
    
    <category term="ClickHouse和他的朋友们" scheme="https://bohutang.me/tags/ClickHouse%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/"/>
    
    <category term="mergetree" scheme="https://bohutang.me/tags/mergetree/"/>
    
    <category term="WAL" scheme="https://bohutang.me/tags/WAL/"/>
    
  </entry>
  
</feed>
